{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee8de2b",
   "metadata": {},
   "source": [
    "### In this notebook we perform federated learning\n",
    "\n",
    "In federated learning each base station has access only to it's private dataset, however they collaborate together to train a model that has satifactory results on data from any other base station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a97e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "parent = Path(os.path.abspath(\"\")).resolve().parents[0]\n",
    "if parent not in sys.path:\n",
    "    sys.path.insert(0, str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed1269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c1ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.utils.data_utils import read_data, generate_time_lags, time_to_feature, handle_nans, to_Xy, \\\n",
    "    to_torch_dataset, to_timeseries_rep, assign_statistics, \\\n",
    "    to_train_val, scale_features, get_data_by_area, remove_identifiers, get_exogenous_data_by_area, handle_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79e4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.utils.train_utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c779c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.models.mlp import MLP\n",
    "from ml.models.rnn import RNN\n",
    "from ml.models.lstm import LSTM\n",
    "from ml.models.gru import GRU\n",
    "from ml.models.cnn import CNN\n",
    "from ml.models.rnn_autoencoder import DualAttentionAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d7baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.fl.defaults import create_regression_client\n",
    "from ml.fl.client_proxy import SimpleClientProxy\n",
    "from ml.fl.server.server import Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4606af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_path='../dataset/full_dataset.csv', # dataset\n",
    "    data_path_test=['../dataset/ElBorn_test.csv'], # test dataset\n",
    "    test_size=0.2, # validation size \n",
    "    targets=['rnti_count', 'rb_down', 'rb_up', 'down', 'up'], # the target columns\n",
    "    num_lags=10, # the number of past observations to feed as input\n",
    "\n",
    "    identifier='District', # the column name that identifies a bs\n",
    "\n",
    "    nan_constant=0, # the constant to transform nan values\n",
    "    x_scaler='minmax', # x_scaler\n",
    "    y_scaler='minmax', # y_scaler\n",
    "    outlier_detection=None, # whether to perform flooring and capping\n",
    "\n",
    "    \n",
    "    criterion='mse', # optimization criterion, mse or l1\n",
    "    fl_rounds=10, # the number of federated rounds\n",
    "    fraction=1., # the percentage of available client to consider for random selection\n",
    "    aggregation=\"fedavg\", # federated aggregation algorithm\n",
    "    epochs=3, # the number of maximum local epochs\n",
    "    lr=0.001, # learning rate\n",
    "    optimizer='adam', # the optimizer, it can be sgd or adam\n",
    "    batch_size=128, # the batch size to use\n",
    "    local_early_stopping=False, # whether to use early stopping\n",
    "    local_patience=50, # patience value for the early stopping parameter (if specified)\n",
    "    max_grad_norm=0.0, # whether to clip grad norm\n",
    "    reg1=0.0, # l1 regularization\n",
    "    reg2=0.0, # l2 regularization\n",
    "\n",
    "    cuda=True, # whether to use gpu\n",
    "    \n",
    "    seed=0, # reproducibility\n",
    "\n",
    "    assign_stats=None, # whether to use statistics as exogenous data, [\"mean\", \"median\", \"std\", \"variance\", \"kurtosis\", \"skew\"]\n",
    "    use_time_features=False # whether to use datetime features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727c20ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script arguments: Namespace(data_path='../dataset/full_dataset.csv', data_path_test=['../dataset/ElBorn_test.csv'], test_size=0.2, targets=['rnti_count', 'rb_down', 'rb_up', 'down', 'up'], num_lags=10, identifier='District', nan_constant=0, x_scaler='minmax', y_scaler='minmax', outlier_detection=None, criterion='mse', fl_rounds=10, fraction=1.0, aggregation='fedavg', epochs=3, lr=0.001, optimizer='adam', batch_size=128, local_early_stopping=False, local_patience=50, max_grad_norm=0.0, reg1=0.0, reg2=0.0, cuda=True, seed=0, assign_stats=None, use_time_features=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Script arguments: {args}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36c3d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if args.cuda and torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28dbb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection specification\n",
    "if args.outlier_detection is not None:\n",
    "    outlier_columns = ['rb_down', 'rb_up', 'down', 'up']\n",
    "    outlier_kwargs = {\"ElBorn\": (10, 90), \"LesCorts\": (10, 90), \"PobleSec\": (5, 95)}\n",
    "    args.outlier_columns = outlier_columns\n",
    "    args.outlier_kwargs = outlier_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7015c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all():\n",
    "    # ensure reproducibility\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581869c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a510771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "022d3623",
   "metadata": {},
   "source": [
    "### The pre-processing method is almost equivalent to centralized learning. The only difference is that the scaling operations are performed individually on each base station. In contrast, in centralized learning the scaling is performed by considering the combined data from all base stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b304bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessing():\n",
    "    \"\"\"Preprocess a given .csv\"\"\"\n",
    "    # read data\n",
    "    df = read_data(args.data_path)\n",
    "    # handle nans\n",
    "    df = handle_nans(train_data=df, constant=args.nan_constant,\n",
    "                     identifier=args.identifier)\n",
    "    # split to train/validation\n",
    "    train_data, val_data = to_train_val(df)\n",
    "    \n",
    "    # handle outliers (if specified)\n",
    "    if args.outlier_detection is not None:\n",
    "        train_data = handle_outliers(df=train_data, columns=args.outlier_columns,\n",
    "                                     identifier=args.identifier, kwargs=args.outlier_kwargs)\n",
    "    \n",
    "    # get X and y\n",
    "    X_train, X_val, y_train, y_val = to_Xy(train_data=train_data, val_data=val_data,\n",
    "                                          targets=args.targets)\n",
    "    \n",
    "    # scale X\n",
    "    X_train, X_val, x_scalers = scale_features(train_data=X_train, val_data=X_val,\n",
    "                                              scaler=args.x_scaler,\n",
    "                                              per_area=True, # the features are scaled locally\n",
    "                                              identifier=args.identifier)\n",
    "    # scale y\n",
    "    y_train, y_val, y_scalers = scale_features(train_data=y_train, val_data=y_val,\n",
    "                                              scaler=args.y_scaler, \n",
    "                                              per_area=True,\n",
    "                                              identifier=args.identifier)\n",
    "    \n",
    "    # generate time lags\n",
    "    X_train = generate_time_lags(X_train, args.num_lags)\n",
    "    X_val = generate_time_lags(X_val, args.num_lags)\n",
    "    y_train = generate_time_lags(y_train, args.num_lags, is_y=True)\n",
    "    y_val = generate_time_lags(y_val, args.num_lags, is_y=True)\n",
    "    \n",
    "    # get datetime features as exogenous data\n",
    "    date_time_df_train = time_to_feature(\n",
    "        X_train, args.use_time_features, identifier=args.identifier\n",
    "    )\n",
    "    date_time_df_val = time_to_feature(\n",
    "        X_val, args.use_time_features, identifier=args.identifier\n",
    "    )\n",
    "    \n",
    "    # get statistics as exogenous data\n",
    "    stats_df_train = assign_statistics(X_train, args.assign_stats, args.num_lags,\n",
    "                                       targets=args.targets, identifier=args.identifier)\n",
    "    stats_df_val = assign_statistics(X_val, args.assign_stats, args.num_lags, \n",
    "                                       targets=args.targets, identifier=args.identifier)\n",
    "    \n",
    "    # concat the exogenous features (if any) to a single dataframe\n",
    "    if date_time_df_train is not None or stats_df_train is not None:\n",
    "        exogenous_data_train = pd.concat([date_time_df_train, stats_df_train], axis=1)\n",
    "        # remove duplicate columns (if any)\n",
    "        exogenous_data_train = exogenous_data_train.loc[:, ~exogenous_data_train.columns.duplicated()].copy()\n",
    "        assert len(exogenous_data_train) == len(X_train) == len(y_train)\n",
    "    else:\n",
    "        exogenous_data_train = None\n",
    "    if date_time_df_val is not None or stats_df_val is not None:\n",
    "        exogenous_data_val = pd.concat([date_time_df_val, stats_df_val], axis=1)\n",
    "        exogenous_data_val = exogenous_data_val.loc[:, ~exogenous_data_val.columns.duplicated()].copy()\n",
    "        assert len(exogenous_data_val) == len(X_val) == len(y_val)\n",
    "    else:\n",
    "        exogenous_data_val = None\n",
    "        \n",
    "    return X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad15f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2022-10-24 23:13:48,390 | data_utils.py:383 | Observations info in ElBorn\n",
      "INFO logger 2022-10-24 23:13:48,390 | data_utils.py:384 | \tTotal number of samples:  4192\n",
      "INFO logger 2022-10-24 23:13:48,390 | data_utils.py:385 | \tNumber of samples for training: 3354\n",
      "INFO logger 2022-10-24 23:13:48,390 | data_utils.py:386 | \tNumber of samples for validation:  838\n",
      "INFO logger 2022-10-24 23:13:48,398 | data_utils.py:383 | Observations info in LesCorts\n",
      "INFO logger 2022-10-24 23:13:48,398 | data_utils.py:384 | \tTotal number of samples:  6892\n",
      "INFO logger 2022-10-24 23:13:48,398 | data_utils.py:385 | \tNumber of samples for training: 5514\n",
      "INFO logger 2022-10-24 23:13:48,398 | data_utils.py:386 | \tNumber of samples for validation:  1378\n",
      "INFO logger 2022-10-24 23:13:48,406 | data_utils.py:383 | Observations info in PobleSec\n",
      "INFO logger 2022-10-24 23:13:48,406 | data_utils.py:384 | \tTotal number of samples:  15927\n",
      "INFO logger 2022-10-24 23:13:48,406 | data_utils.py:385 | \tNumber of samples for training: 12742\n",
      "INFO logger 2022-10-24 23:13:48,406 | data_utils.py:386 | \tNumber of samples for validation:  3185\n",
      "INFO logger 2022-10-24 23:13:48,406 | data_utils.py:389 | Observations info using all data\n",
      "INFO logger 2022-10-24 23:13:48,415 | data_utils.py:390 | \tTotal number of samples:  27011\n",
      "INFO logger 2022-10-24 23:13:48,415 | data_utils.py:391 | \tNumber of samples for training: 21610\n",
      "INFO logger 2022-10-24 23:13:48,415 | data_utils.py:392 | \tNumber of samples for validation:  5401\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers = make_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0982ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rb_up_var_lag-10</th>\n",
       "      <th>rb_up_lag-10</th>\n",
       "      <th>rb_down_var_lag-10</th>\n",
       "      <th>rb_down_lag-10</th>\n",
       "      <th>mcs_up_var_lag-10</th>\n",
       "      <th>mcs_up_lag-10</th>\n",
       "      <th>mcs_down_var_lag-10</th>\n",
       "      <th>mcs_down_lag-10</th>\n",
       "      <th>rnti_count_lag-10</th>\n",
       "      <th>up_lag-10</th>\n",
       "      <th>...</th>\n",
       "      <th>rb_down_var_lag-1</th>\n",
       "      <th>rb_down_lag-1</th>\n",
       "      <th>mcs_up_var_lag-1</th>\n",
       "      <th>mcs_up_lag-1</th>\n",
       "      <th>mcs_down_var_lag-1</th>\n",
       "      <th>mcs_down_lag-1</th>\n",
       "      <th>rnti_count_lag-1</th>\n",
       "      <th>up_lag-1</th>\n",
       "      <th>down_lag-1</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:16:00</th>\n",
       "      <td>3.143298e-08</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>2.677239e-08</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>0.207425</td>\n",
       "      <td>0.483274</td>\n",
       "      <td>0.796265</td>\n",
       "      <td>0.929664</td>\n",
       "      <td>0.227829</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>...</td>\n",
       "      <td>2.890976e-08</td>\n",
       "      <td>0.052571</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>0.478785</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>0.275640</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.108785</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:18:00</th>\n",
       "      <td>4.439640e-08</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>2.795076e-08</td>\n",
       "      <td>0.052412</td>\n",
       "      <td>0.259314</td>\n",
       "      <td>0.530084</td>\n",
       "      <td>0.796778</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>0.273796</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>...</td>\n",
       "      <td>2.742117e-08</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>0.242482</td>\n",
       "      <td>0.499756</td>\n",
       "      <td>0.783107</td>\n",
       "      <td>0.922241</td>\n",
       "      <td>0.274142</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.108356</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:20:00</th>\n",
       "      <td>2.993595e-08</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>2.825645e-08</td>\n",
       "      <td>0.047602</td>\n",
       "      <td>0.261772</td>\n",
       "      <td>0.512427</td>\n",
       "      <td>0.797310</td>\n",
       "      <td>0.921577</td>\n",
       "      <td>0.249107</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>...</td>\n",
       "      <td>2.813661e-08</td>\n",
       "      <td>0.051305</td>\n",
       "      <td>0.241381</td>\n",
       "      <td>0.450879</td>\n",
       "      <td>0.800429</td>\n",
       "      <td>0.920308</td>\n",
       "      <td>0.269116</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.106185</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:22:00</th>\n",
       "      <td>5.382563e-08</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>2.711694e-08</td>\n",
       "      <td>0.060476</td>\n",
       "      <td>0.320280</td>\n",
       "      <td>0.506925</td>\n",
       "      <td>0.782003</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.315683</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>...</td>\n",
       "      <td>2.869276e-08</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.315197</td>\n",
       "      <td>0.495057</td>\n",
       "      <td>0.814955</td>\n",
       "      <td>0.917776</td>\n",
       "      <td>0.317020</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.127269</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:24:00</th>\n",
       "      <td>5.922178e-08</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>2.835084e-08</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.286799</td>\n",
       "      <td>0.497228</td>\n",
       "      <td>0.781283</td>\n",
       "      <td>0.919718</td>\n",
       "      <td>0.343507</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695933e-08</td>\n",
       "      <td>0.042399</td>\n",
       "      <td>0.267656</td>\n",
       "      <td>0.452835</td>\n",
       "      <td>0.792680</td>\n",
       "      <td>0.919174</td>\n",
       "      <td>0.226423</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.088458</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rb_up_var_lag-10  rb_up_lag-10  rb_down_var_lag-10  \\\n",
       "time                                                                      \n",
       "2018-03-28 16:16:00      3.143298e-08      0.002418        2.677239e-08   \n",
       "2018-03-28 16:18:00      4.439640e-08      0.003812        2.795076e-08   \n",
       "2018-03-28 16:20:00      2.993595e-08      0.002716        2.825645e-08   \n",
       "2018-03-28 16:22:00      5.382563e-08      0.004139        2.711694e-08   \n",
       "2018-03-28 16:24:00      5.922178e-08      0.004565        2.835084e-08   \n",
       "\n",
       "                     rb_down_lag-10  mcs_up_var_lag-10  mcs_up_lag-10  \\\n",
       "time                                                                    \n",
       "2018-03-28 16:16:00        0.043020           0.207425       0.483274   \n",
       "2018-03-28 16:18:00        0.052412           0.259314       0.530084   \n",
       "2018-03-28 16:20:00        0.047602           0.261772       0.512427   \n",
       "2018-03-28 16:22:00        0.060476           0.320280       0.506925   \n",
       "2018-03-28 16:24:00        0.066004           0.286799       0.497228   \n",
       "\n",
       "                     mcs_down_var_lag-10  mcs_down_lag-10  rnti_count_lag-10  \\\n",
       "time                                                                           \n",
       "2018-03-28 16:16:00             0.796265         0.929664           0.227829   \n",
       "2018-03-28 16:18:00             0.796778         0.914716           0.273796   \n",
       "2018-03-28 16:20:00             0.797310         0.921577           0.249107   \n",
       "2018-03-28 16:22:00             0.782003         0.916003           0.315683   \n",
       "2018-03-28 16:24:00             0.781283         0.919718           0.343507   \n",
       "\n",
       "                     up_lag-10  ...  rb_down_var_lag-1  rb_down_lag-1  \\\n",
       "time                            ...                                     \n",
       "2018-03-28 16:16:00   0.002758  ...       2.890976e-08       0.052571   \n",
       "2018-03-28 16:18:00   0.004257  ...       2.742117e-08       0.052254   \n",
       "2018-03-28 16:20:00   0.002874  ...       2.813661e-08       0.051305   \n",
       "2018-03-28 16:22:00   0.004442  ...       2.869276e-08       0.061644   \n",
       "2018-03-28 16:24:00   0.004884  ...       2.695933e-08       0.042399   \n",
       "\n",
       "                     mcs_up_var_lag-1  mcs_up_lag-1  mcs_down_var_lag-1  \\\n",
       "time                                                                      \n",
       "2018-03-28 16:16:00          0.232918      0.478785            0.793296   \n",
       "2018-03-28 16:18:00          0.242482      0.499756            0.783107   \n",
       "2018-03-28 16:20:00          0.241381      0.450879            0.800429   \n",
       "2018-03-28 16:22:00          0.315197      0.495057            0.814955   \n",
       "2018-03-28 16:24:00          0.267656      0.452835            0.792680   \n",
       "\n",
       "                     mcs_down_lag-1  rnti_count_lag-1  up_lag-1  down_lag-1  \\\n",
       "time                                                                          \n",
       "2018-03-28 16:16:00        0.916750          0.275640  0.003258    0.108785   \n",
       "2018-03-28 16:18:00        0.922241          0.274142  0.003790    0.108356   \n",
       "2018-03-28 16:20:00        0.920308          0.269116  0.002989    0.106185   \n",
       "2018-03-28 16:22:00        0.917776          0.317020  0.004932    0.127269   \n",
       "2018-03-28 16:24:00        0.919174          0.226423  0.002596    0.088458   \n",
       "\n",
       "                     District  \n",
       "time                           \n",
       "2018-03-28 16:16:00    ElBorn  \n",
       "2018-03-28 16:18:00    ElBorn  \n",
       "2018-03-28 16:20:00    ElBorn  \n",
       "2018-03-28 16:22:00    ElBorn  \n",
       "2018-03-28 16:24:00    ElBorn  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5e37966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnti_count</th>\n",
       "      <th>rb_down</th>\n",
       "      <th>rb_up</th>\n",
       "      <th>down</th>\n",
       "      <th>up</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:16:00</th>\n",
       "      <td>0.274142</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.108356</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:18:00</th>\n",
       "      <td>0.269116</td>\n",
       "      <td>0.051305</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.106185</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:20:00</th>\n",
       "      <td>0.317020</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.127269</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:22:00</th>\n",
       "      <td>0.226423</td>\n",
       "      <td>0.042399</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.088458</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:24:00</th>\n",
       "      <td>0.307914</td>\n",
       "      <td>0.058735</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.122086</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rnti_count   rb_down     rb_up      down        up  \\\n",
       "time                                                                      \n",
       "2018-03-28 16:16:00    0.274142  0.052254  0.003433  0.108356  0.003790   \n",
       "2018-03-28 16:18:00    0.269116  0.051305  0.002995  0.106185  0.002989   \n",
       "2018-03-28 16:20:00    0.317020  0.061644  0.004508  0.127269  0.004932   \n",
       "2018-03-28 16:22:00    0.226423  0.042399  0.002672  0.088458  0.002596   \n",
       "2018-03-28 16:24:00    0.307914  0.058735  0.003842  0.122086  0.004053   \n",
       "\n",
       "                    District  \n",
       "time                          \n",
       "2018-03-28 16:16:00   ElBorn  \n",
       "2018-03-28 16:18:00   ElBorn  \n",
       "2018-03-28 16:20:00   ElBorn  \n",
       "2018-03-28 16:22:00   ElBorn  \n",
       "2018-03-28 16:24:00   ElBorn  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02cb4089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ElBorn': MinMaxScaler(),\n",
       "  'LesCorts': MinMaxScaler(),\n",
       "  'PobleSec': MinMaxScaler()},\n",
       " {'ElBorn': MinMaxScaler(),\n",
       "  'LesCorts': MinMaxScaler(),\n",
       "  'PobleSec': MinMaxScaler()})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scalers, y_scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a26b1",
   "metadata": {},
   "source": [
    "### Postprocessing in a same manner with centalized learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff4401b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers):\n",
    "    \"\"\"Make data ready to be fed into ml algorithms\"\"\"\n",
    "    # if there are more than one specified areas, get the data per area\n",
    "    if X_train[args.identifier].nunique() != 1:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = get_data_by_area(X_train, X_val,\n",
    "                                                                              y_train, y_val, \n",
    "                                                                              identifier=args.identifier)\n",
    "    else:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = None, None, None, None\n",
    "\n",
    "    # Get the exogenous data per area.\n",
    "    if exogenous_data_train is not None:\n",
    "        exogenous_data_train, exogenous_data_val = get_exogenous_data_by_area(exogenous_data_train,\n",
    "                                                                              exogenous_data_val)\n",
    "    # transform to np\n",
    "    if area_X_train is not None:\n",
    "        for area in area_X_train:\n",
    "            tmp_X_train, tmp_y_train, tmp_X_val, tmp_y_val = remove_identifiers(\n",
    "                area_X_train[area], area_y_train[area], area_X_val[area], area_y_val[area])\n",
    "            tmp_X_train, tmp_y_train = tmp_X_train.to_numpy(), tmp_y_train.to_numpy()\n",
    "            tmp_X_val, tmp_y_val = tmp_X_val.to_numpy(), tmp_y_val.to_numpy()\n",
    "            area_X_train[area] = tmp_X_train\n",
    "            area_X_val[area] = tmp_X_val\n",
    "            area_y_train[area] = tmp_y_train\n",
    "            area_y_val[area] = tmp_y_val\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train[area] = exogenous_data_train[area].to_numpy()\n",
    "            exogenous_data_val[area] = exogenous_data_val[area].to_numpy()\n",
    "    \n",
    "    # remove identifiers from features, targets\n",
    "    X_train, y_train, X_val, y_val = remove_identifiers(X_train, y_train, X_val, y_val)\n",
    "    assert len(X_train.columns) == len(X_val.columns)\n",
    "    \n",
    "    num_features = len(X_train.columns) // args.num_lags\n",
    "    \n",
    "    # to timeseries representation\n",
    "    X_train = to_timeseries_rep(X_train.to_numpy(), num_lags=args.num_lags,\n",
    "                                            num_features=num_features)\n",
    "    X_val = to_timeseries_rep(X_val.to_numpy(), num_lags=args.num_lags,\n",
    "                                          num_features=num_features)\n",
    "    \n",
    "    if area_X_train is not None:\n",
    "        area_X_train = to_timeseries_rep(area_X_train, num_lags=args.num_lags,\n",
    "                                                     num_features=num_features)\n",
    "        area_X_val = to_timeseries_rep(area_X_val, num_lags=args.num_lags,\n",
    "                                                   num_features=num_features)\n",
    "    \n",
    "    # transform targets to numpy\n",
    "    y_train, y_val = y_train.to_numpy(), y_val.to_numpy()\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        exogenous_data_train_combined, exogenous_data_val_combined = [], []\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train_combined.extend(exogenous_data_train[area])\n",
    "            exogenous_data_val_combined.extend(exogenous_data_val[area])\n",
    "        exogenous_data_train_combined = np.stack(exogenous_data_train_combined)\n",
    "        exogenous_data_val_combined = np.stack(exogenous_data_val_combined)\n",
    "        exogenous_data_train[\"all\"] = exogenous_data_train_combined\n",
    "        exogenous_data_val[\"all\"] = exogenous_data_val_combined\n",
    "    return X_train, X_val, y_train, y_val, area_X_train, area_X_val, area_y_train, area_y_val, exogenous_data_train, exogenous_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03064d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, client_X_train, client_X_val, client_y_train, client_y_val, exogenous_data_train, exogenous_data_val = make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee088254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ElBorn', 'LesCorts', 'PobleSec'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aef6d703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ElBorn', 'LesCorts', 'PobleSec'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_X_val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfe82601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Client: ElBorn\n",
      "X_train shape: (3344, 10, 11, 1), y_train shape: (3344, 5)\n",
      "X_val shape: (828, 10, 11, 1), y_val shape: (828, 5)\n",
      "\n",
      "Client: LesCorts\n",
      "X_train shape: (5504, 10, 11, 1), y_train shape: (5504, 5)\n",
      "X_val shape: (1368, 10, 11, 1), y_val shape: (1368, 5)\n",
      "\n",
      "Client: PobleSec\n",
      "X_train shape: (12732, 10, 11, 1), y_train shape: (12732, 5)\n",
      "X_val shape: (3175, 10, 11, 1), y_val shape: (3175, 5)\n"
     ]
    }
   ],
   "source": [
    "for client in client_X_train:\n",
    "    print(f\"\\nClient: {client}\")\n",
    "    print(f\"X_train shape: {client_X_train[client].shape}, y_train shape: {client_y_train[client].shape}\")\n",
    "    print(f\"X_val shape: {client_X_val[client].shape}, y_val shape: {client_y_val[client].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922abedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c20f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dims(X_train, exogenous_data_train):\n",
    "    if args.model_name == \"mlp\":\n",
    "        input_dim = X_train.shape[1] * X_train.shape[2]\n",
    "    else:\n",
    "        input_dim = X_train.shape[2]\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        if len(exogenous_data_train) == 1:\n",
    "            cid = next(iter(exogenous_data_train.keys()))\n",
    "            exogenous_dim = exogenous_data_train[cid].shape[1]\n",
    "        else:\n",
    "            exogenous_dim = exogenous_data_train[\"all\"].shape[1]\n",
    "    else:\n",
    "        exogenous_dim = 0\n",
    "    \n",
    "    return input_dim, exogenous_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e866f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model: str,\n",
    "              input_dim: int,\n",
    "              out_dim: int,\n",
    "              lags: int = 10,\n",
    "              exogenous_dim: int = 0,\n",
    "              seed=0):\n",
    "    if model == \"mlp\":\n",
    "        model = MLP(input_dim=input_dim, layer_units=[256, 128, 64], num_outputs=out_dim)\n",
    "    elif model == \"rnn\":\n",
    "        model = RNN(input_dim=input_dim, rnn_hidden_size=128, num_rnn_layers=1, rnn_dropout=0.0,\n",
    "                    layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"lstm\":\n",
    "        model = LSTM(input_dim=input_dim, lstm_hidden_size=128, num_lstm_layers=1, lstm_dropout=0.0,\n",
    "                     layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"gru\":\n",
    "        model = GRU(input_dim=input_dim, gru_hidden_size=128, num_gru_layers=1, gru_dropout=0.0,\n",
    "                    layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"cnn\":\n",
    "        model = CNN(num_features=input_dim, lags=lags, exogenous_dim=exogenous_dim, out_dim=out_dim)\n",
    "    elif model == \"da_encoder_decoder\":\n",
    "        model = DualAttentionAutoEncoder(input_dim=input_dim, architecture=\"lstm\", matrix_rep=True)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Specified model is not implemented. Plese define your own model or choose one from ['mlp', 'rnn', 'lstm', 'gru', 'cnn', 'da_encoder_decoder']\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e163843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "args.model_name = \"cnn\"\n",
    "\n",
    "input_dim, exogenous_dim = get_input_dims(X_train, exogenous_data_train)\n",
    "\n",
    "print(input_dim, exogenous_dim)\n",
    "\n",
    "model = get_model(model=args.model_name,\n",
    "                  input_dim=input_dim,\n",
    "                  out_dim=y_train.shape[1],\n",
    "                  lags=args.num_lags,\n",
    "                  exogenous_dim=exogenous_dim,\n",
    "                  seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e15bd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (activation): ReLU()\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(16, 3), stride=(1, 1), padding=same)\n",
       "  (conv2): Conv2d(16, 16, kernel_size=(3, 5), stride=(1, 1), padding=same)\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(4, 3), stride=(1, 1), padding=same)\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(4, 3), stride=(1, 1), padding=same)\n",
       "  (pool): AvgPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0)\n",
       "  (fc): Linear(in_features=1760, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2813c1",
   "metadata": {},
   "source": [
    "### Fit function initiates the training process of every base station local model and then performs parameters aggregation on a central server for N specified federated epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a913bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, X_train, y_train, X_val, y_val, \n",
    "        exogenous_data_train=None, exogenous_data_val=None, \n",
    "        idxs=[8, 3, 1, 10, 9], # the indices of our targets in X\n",
    "        log_per=1,\n",
    "        client_creation_fn = None, # client specification\n",
    "        local_train_params=None, # local params\n",
    "        aggregation_params=None, # aggregation params\n",
    "        use_carbontracker=True\n",
    "       ):\n",
    "    # client creation definition\n",
    "    if client_creation_fn is None:\n",
    "        client_creation_fn = create_regression_client\n",
    "    # local params\n",
    "    if local_train_params is None:\n",
    "        local_train_params = {\n",
    "            \"epochs\": args.epochs, \"optimizer\": args.optimizer, \"lr\": args.lr,\n",
    "            \"criterion\": args.criterion, \"early_stopping\": args.local_early_stopping,\n",
    "            \"patience\": args.local_patience, \"device\": device\n",
    "        }\n",
    "    \n",
    "    train_loaders, val_loaders = [], []\n",
    "    \n",
    "    # get data per client\n",
    "    for client in X_train:\n",
    "        if client == \"all\":\n",
    "            continue\n",
    "        if exogenous_data_train is not None:\n",
    "            tmp_exogenous_data_train = exogenous_data_train[client]\n",
    "            tmp_exogenous_data_val = tmp_exogenous_data_val[client]\n",
    "        else:\n",
    "            tmp_exogenous_data_train = None\n",
    "            tmp_exogenous_data_val = None\n",
    "    \n",
    "        num_features = len(X_train[client][0][0])\n",
    "        \n",
    "        # to torch loader\n",
    "        train_loaders.append(\n",
    "            to_torch_dataset(\n",
    "                X_train[client], y_train[client],\n",
    "                num_lags=args.num_lags,\n",
    "                num_features=num_features,\n",
    "                exogenous_data=tmp_exogenous_data_train,\n",
    "                indices=idxs,\n",
    "                batch_size=args.batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "        )\n",
    "        val_loaders.append(\n",
    "            to_torch_dataset(\n",
    "                X_val[client], y_val[client],\n",
    "                num_lags=args.num_lags,\n",
    "                exogenous_data=tmp_exogenous_data_val,\n",
    "                indices=idxs,\n",
    "                batch_size=args.batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "        )\n",
    "        \n",
    "    # create clients with their local data\n",
    "    cids = [k for k in X_train.keys() if k != \"all\"]\n",
    "    clients = [\n",
    "        client_creation_fn(\n",
    "            cid=cid, # client id\n",
    "            model=model, # the global model\n",
    "            train_loader=train_loader, # the local train loader\n",
    "            test_loader=val_loader, # the local val loader\n",
    "            local_params=local_train_params # local parameters\n",
    "        )\n",
    "        for cid, train_loader, val_loader in zip(cids, train_loaders, val_loaders)\n",
    "    ]\n",
    "    \n",
    "    # represent clients to server\n",
    "    client_proxies = [\n",
    "        SimpleClientProxy(cid, client) for cid, client in zip(cids, clients)\n",
    "    ]\n",
    "    \n",
    "    # represent the server\n",
    "    server = Server(\n",
    "        client_proxies=client_proxies, # the client representations\n",
    "        aggregation=args.aggregation, # the aggregation algorithm\n",
    "        aggregation_params=aggregation_params, # aggregation specific params\n",
    "        local_params_fn=None, # we can change the local params on demand\n",
    "    )\n",
    "    # Note that the client manager instance will be initialized automatically. You can define your own client manager.\n",
    "\n",
    "    # train with FL\n",
    "    model_params, history = server.fit(args.fl_rounds, args.fraction, use_carbontracker=use_carbontracker)\n",
    "    \n",
    "    params_dict = zip(model.state_dict().keys(), model_params)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    model = copy.deepcopy(model)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51240332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated local params\n",
    "local_train_params = {\"epochs\": args.epochs, \"optimizer\": args.optimizer, \"lr\": args.lr,\n",
    "                      \"criterion\": args.criterion, \"early_stopping\": args.local_early_stopping,\n",
    "                      \"patience\": args.local_patience, \"device\": device\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1054cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2022-10-24 23:13:52,924 | server.py:62 | Initializing client manager...\n",
      "INFO logger 2022-10-24 23:13:52,924 | server.py:69 | Registering clients...\n",
      "INFO logger 2022-10-24 23:13:52,924 | client_manager.py:66 | Registered client with id: ElBorn\n",
      "INFO logger 2022-10-24 23:13:52,924 | client_manager.py:66 | Registered client with id: LesCorts\n",
      "INFO logger 2022-10-24 23:13:52,924 | client_manager.py:66 | Registered client with id: PobleSec\n",
      "INFO logger 2022-10-24 23:13:52,932 | server.py:73 | Client manager initialized!\n",
      "INFO logger 2022-10-24 23:13:52,932 | server.py:55 | Aggregation algorithm: FedAvg()\n",
      "INFO logger 2022-10-24 23:13:52,932 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts']\n",
      "c:\\Users\\nikop\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\\aten\\src\\ATen\\native\\Convolution.cpp:647.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "INFO logger 2022-10-24 23:13:57,474 | server.py:86 | Starting FL rounds\n",
      "INFO logger 2022-10-24 23:13:57,791 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['LesCorts', 'ElBorn', 'PobleSec']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: The following components were found: GPU with device(s) NVIDIA GeForce GTX 1650 Ti.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2022-10-24 23:14:00,201 | train_utils.py:142 | Best Loss: 1.638515244615237e-05\n",
      "INFO logger 2022-10-24 23:14:02,399 | train_utils.py:142 | Best Loss: 3.2951381799297022e-06\n",
      "INFO logger 2022-10-24 23:14:06,641 | train_utils.py:142 | Best Loss: 1.6769740646191704e-05\n",
      "INFO logger 2022-10-24 23:14:07,102 | server.py:191 | [Global round 1] Aggregating local models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarbonTracker: \n",
      "Actual consumption for 1 epoch(s):\n",
      "\tTime:\t0:00:09\n",
      "\tEnergy:\t0.000055 kWh\n",
      "\tCO2eq:\t0.016141 g\n",
      "\tThis is equivalent to:\n",
      "\t0.000134 km travelled by car\n",
      "CarbonTracker: \n",
      "Predicted consumption for 10 epoch(s):\n",
      "\tTime:\t0:01:33\n",
      "\tEnergy:\t0.000549 kWh\n",
      "\tCO2eq:\t0.161412 g\n",
      "\tThis is equivalent to:\n",
      "\t0.001341 km travelled by car\n",
      "CarbonTracker: Finished monitoring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2022-10-24 23:14:09,559 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['PobleSec', 'LesCorts', 'ElBorn']\n",
      "INFO logger 2022-10-24 23:14:16,032 | train_utils.py:142 | Best Loss: 1.580404676863645e-05\n",
      "INFO logger 2022-10-24 23:14:18,205 | train_utils.py:142 | Best Loss: 1.4189285691997734e-05\n",
      "INFO logger 2022-10-24 23:14:19,438 | train_utils.py:142 | Best Loss: 9.230368898322149e-06\n",
      "INFO logger 2022-10-24 23:14:19,638 | server.py:191 | [Global round 2] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:14:20,447 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['LesCorts', 'PobleSec', 'ElBorn']\n",
      "INFO logger 2022-10-24 23:14:22,213 | train_utils.py:142 | Best Loss: 1.3335206044997138e-05\n",
      "INFO logger 2022-10-24 23:14:28,674 | train_utils.py:142 | Best Loss: 1.575978745992376e-05\n",
      "INFO logger 2022-10-24 23:14:30,376 | train_utils.py:142 | Best Loss: 4.586990992144956e-06\n",
      "INFO logger 2022-10-24 23:14:30,523 | server.py:191 | [Global round 3] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:14:31,445 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['PobleSec', 'ElBorn', 'LesCorts']\n",
      "INFO logger 2022-10-24 23:14:37,398 | train_utils.py:142 | Best Loss: 1.520014505496058e-05\n",
      "INFO logger 2022-10-24 23:14:39,908 | train_utils.py:142 | Best Loss: 4.70423503499928e-06\n",
      "INFO logger 2022-10-24 23:14:42,071 | train_utils.py:142 | Best Loss: 1.3191093237456533e-05\n",
      "INFO logger 2022-10-24 23:14:42,269 | server.py:191 | [Global round 4] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:14:43,127 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['LesCorts', 'ElBorn', 'PobleSec']\n",
      "INFO logger 2022-10-24 23:14:45,268 | train_utils.py:142 | Best Loss: 1.3087921881740532e-05\n",
      "INFO logger 2022-10-24 23:14:46,567 | train_utils.py:142 | Best Loss: 6.026086058064954e-06\n",
      "INFO logger 2022-10-24 23:14:50,612 | train_utils.py:142 | Best Loss: 1.4954684861371015e-05\n",
      "INFO logger 2022-10-24 23:14:51,124 | server.py:191 | [Global round 5] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:14:51,905 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['PobleSec', 'LesCorts', 'ElBorn']\n",
      "INFO logger 2022-10-24 23:14:57,142 | train_utils.py:142 | Best Loss: 1.4808487585254425e-05\n",
      "INFO logger 2022-10-24 23:15:07,754 | train_utils.py:142 | Best Loss: 1.2825254493186043e-05\n",
      "INFO logger 2022-10-24 23:15:09,565 | train_utils.py:142 | Best Loss: 6.586943408879249e-06\n",
      "INFO logger 2022-10-24 23:15:09,772 | server.py:191 | [Global round 6] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:15:11,008 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['LesCorts', 'ElBorn', 'PobleSec']\n",
      "INFO logger 2022-10-24 23:15:13,288 | train_utils.py:142 | Best Loss: 1.2540215832638768e-05\n",
      "INFO logger 2022-10-24 23:15:15,052 | train_utils.py:142 | Best Loss: 2.894626537665212e-06\n",
      "INFO logger 2022-10-24 23:15:21,335 | train_utils.py:142 | Best Loss: 1.456983441552954e-05\n",
      "INFO logger 2022-10-24 23:15:21,997 | server.py:191 | [Global round 7] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:15:23,239 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['PobleSec', 'LesCorts', 'ElBorn']\n",
      "INFO logger 2022-10-24 23:15:29,541 | train_utils.py:142 | Best Loss: 1.461888828468839e-05\n",
      "INFO logger 2022-10-24 23:15:32,811 | train_utils.py:142 | Best Loss: 1.2955778960563374e-05\n",
      "INFO logger 2022-10-24 23:15:34,596 | train_utils.py:142 | Best Loss: 2.3921925781501664e-06\n",
      "INFO logger 2022-10-24 23:15:34,778 | server.py:191 | [Global round 8] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:15:35,926 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['PobleSec', 'ElBorn', 'LesCorts']\n",
      "INFO logger 2022-10-24 23:15:41,418 | train_utils.py:142 | Best Loss: 1.4465245927911339e-05\n",
      "INFO logger 2022-10-24 23:15:43,682 | train_utils.py:142 | Best Loss: 2.5245345845494582e-06\n",
      "INFO logger 2022-10-24 23:15:46,537 | train_utils.py:142 | Best Loss: 1.290796919622355e-05\n",
      "INFO logger 2022-10-24 23:15:46,838 | server.py:191 | [Global round 9] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:15:48,089 | client_manager.py:88 | Parameter c=1.0. Sampled 3 client(s): ['LesCorts', 'PobleSec', 'ElBorn']\n",
      "INFO logger 2022-10-24 23:15:50,494 | train_utils.py:142 | Best Loss: 1.2467856221418413e-05\n",
      "INFO logger 2022-10-24 23:15:56,250 | train_utils.py:142 | Best Loss: 1.4547477787961875e-05\n",
      "INFO logger 2022-10-24 23:15:58,531 | train_utils.py:142 | Best Loss: 2.1839770263483847e-06\n",
      "INFO logger 2022-10-24 23:15:58,714 | server.py:191 | [Global round 10] Aggregating local models...\n",
      "INFO logger 2022-10-24 23:15:59,924 | server.py:112 | Time passed: 122.13360929489136 seconds.\n",
      "INFO logger 2022-10-24 23:15:59,924 | server.py:113 | Best global model found on fl_round=10 with loss=1.7617426737892406e-05\n"
     ]
    }
   ],
   "source": [
    "global_model, history = fit(\n",
    "    model,\n",
    "    client_X_train,\n",
    "    client_y_train, \n",
    "    client_X_val, \n",
    "    client_y_val, \n",
    "    local_train_params=local_train_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfb2ead6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-4.4958e-03,  1.0610e-01, -1.8101e-02],\n",
       "                        [ 5.7758e-02, -5.1433e-02,  3.1065e-02],\n",
       "                        [-1.0231e-01,  4.6284e-02, -4.5668e-02],\n",
       "                        [-4.7838e-02, -2.3001e-02, -6.6809e-02],\n",
       "                        [-2.9614e-02,  3.1829e-03, -2.6900e-02],\n",
       "                        [-4.6026e-02,  5.3621e-03,  1.1022e-01],\n",
       "                        [ 2.0108e-02,  3.4129e-02,  3.8213e-02],\n",
       "                        [ 3.6525e-02, -1.5622e-02, -4.7462e-02],\n",
       "                        [-7.4194e-02, -9.0040e-02,  3.7335e-03],\n",
       "                        [-2.1357e-02, -6.1253e-02,  7.0864e-02],\n",
       "                        [ 3.0791e-02,  4.4030e-03,  7.7984e-02],\n",
       "                        [-5.6613e-02, -4.2900e-02,  4.3043e-02],\n",
       "                        [ 1.3947e-01, -7.9259e-03, -1.8361e-02],\n",
       "                        [ 4.2853e-02, -1.1919e-01, -1.1483e-03],\n",
       "                        [-5.9175e-02, -1.5662e-01,  3.6776e-03],\n",
       "                        [-7.5070e-02,  9.4104e-03, -1.9517e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7367e-02,  2.2396e-02,  2.4955e-02],\n",
       "                        [-3.4879e-02, -3.3812e-02,  5.2683e-02],\n",
       "                        [-1.2334e-02, -9.5421e-03,  2.4417e-02],\n",
       "                        [-4.4772e-02, -2.9350e-02, -1.4126e-02],\n",
       "                        [ 7.2237e-02, -4.9726e-02, -3.4043e-02],\n",
       "                        [-1.6918e-03,  1.7279e-02, -5.2873e-03],\n",
       "                        [-5.2289e-02, -5.2548e-02,  5.0714e-02],\n",
       "                        [ 8.4973e-02, -5.9742e-02, -2.5254e-02],\n",
       "                        [-9.8608e-02,  7.8702e-02, -7.3470e-02],\n",
       "                        [-5.9146e-02, -2.3648e-02, -1.9591e-02],\n",
       "                        [ 2.0824e-02, -5.4868e-02, -5.5016e-02],\n",
       "                        [ 3.6217e-02,  2.0025e-02, -1.0464e-01],\n",
       "                        [ 4.2609e-02,  8.1379e-02, -3.5806e-02],\n",
       "                        [ 9.7583e-02,  1.2478e-01, -1.4561e-01],\n",
       "                        [-2.5286e-02,  1.8083e-01, -1.0338e-01],\n",
       "                        [ 5.9649e-02,  3.0466e-02, -4.6114e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5996e-02, -7.6584e-02, -7.7983e-02],\n",
       "                        [-4.6780e-02,  6.3716e-02,  4.0605e-02],\n",
       "                        [ 5.0161e-02, -3.6297e-02, -7.2388e-02],\n",
       "                        [ 6.8248e-02, -5.5059e-02, -3.3304e-02],\n",
       "                        [ 8.0165e-04,  5.2284e-02,  2.3273e-02],\n",
       "                        [ 3.8703e-03,  5.9677e-02,  9.4110e-02],\n",
       "                        [ 4.6566e-02,  3.0023e-02,  1.4460e-02],\n",
       "                        [-1.2913e-01,  9.5066e-02, -1.0150e-02],\n",
       "                        [-8.5069e-02, -5.6849e-02, -1.2215e-01],\n",
       "                        [-7.1914e-02,  1.9961e-03, -1.2666e-01],\n",
       "                        [-2.4681e-03, -3.3460e-03, -5.0406e-02],\n",
       "                        [-7.0749e-02, -8.6016e-02, -6.5837e-02],\n",
       "                        [ 4.6569e-02,  7.7083e-02,  1.4165e-02],\n",
       "                        [-4.1579e-02, -4.6810e-03,  4.0049e-02],\n",
       "                        [-1.5114e-01,  1.6309e-01,  1.3641e-01],\n",
       "                        [-4.4079e-02,  2.4471e-01, -3.1446e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1264e-02, -1.9435e-02,  4.8899e-03],\n",
       "                        [-4.1153e-02,  5.4735e-02, -4.3138e-02],\n",
       "                        [ 5.7619e-02, -3.8158e-03,  3.3474e-02],\n",
       "                        [-7.4731e-02,  3.2150e-02,  6.8195e-02],\n",
       "                        [-6.9230e-02, -7.0607e-02,  4.3631e-02],\n",
       "                        [ 2.6949e-02,  3.2262e-02,  1.9371e-02],\n",
       "                        [-3.7997e-02,  2.7871e-02,  2.3066e-02],\n",
       "                        [-5.6086e-02, -7.6693e-02, -6.4604e-02],\n",
       "                        [ 1.1265e-02, -9.8173e-03, -1.4354e-02],\n",
       "                        [ 4.2417e-02,  2.1701e-02,  2.5359e-02],\n",
       "                        [-6.6048e-02,  3.9589e-02,  1.8060e-02],\n",
       "                        [-3.7110e-03,  1.0452e-01,  6.8852e-02],\n",
       "                        [-6.5126e-02, -4.7421e-02,  1.0314e-01],\n",
       "                        [-1.3200e-01,  1.3116e-01,  2.1911e-02],\n",
       "                        [-1.6652e-01,  1.1524e-01,  5.8637e-02],\n",
       "                        [-2.0273e-01,  2.0260e-01,  4.4594e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.8154e-02,  1.2227e-02,  3.7859e-02],\n",
       "                        [-7.1002e-02, -3.9397e-02, -1.6524e-02],\n",
       "                        [ 4.3569e-03,  8.6895e-02,  6.2927e-03],\n",
       "                        [ 7.4986e-02, -7.7033e-02,  1.3903e-03],\n",
       "                        [ 9.3869e-03, -2.5840e-02,  2.9176e-02],\n",
       "                        [-6.5387e-03,  9.1951e-03, -3.3585e-02],\n",
       "                        [ 9.5726e-03,  4.7160e-03, -2.8493e-03],\n",
       "                        [ 1.0968e-01, -7.4176e-02,  1.0721e-01],\n",
       "                        [-1.0200e-02, -1.9232e-01,  4.3661e-02],\n",
       "                        [-1.1008e-01,  4.9123e-02,  9.4003e-02],\n",
       "                        [-3.9283e-02, -6.8076e-02, -8.2716e-02],\n",
       "                        [ 9.7187e-03,  3.2272e-04, -1.2432e-01],\n",
       "                        [-3.1040e-02,  9.0718e-02, -4.3998e-02],\n",
       "                        [ 1.2870e-01, -1.0156e-02, -2.1513e-02],\n",
       "                        [-8.9523e-02, -3.2399e-02, -5.7467e-02],\n",
       "                        [ 5.0173e-03,  1.9733e-01,  1.4325e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9687e-02,  4.0554e-02,  1.4562e-02],\n",
       "                        [-1.2687e-02, -1.2139e-02, -4.3113e-02],\n",
       "                        [-3.1494e-03, -1.3926e-02,  3.6759e-02],\n",
       "                        [-2.2637e-02, -9.1192e-02,  5.4690e-02],\n",
       "                        [ 6.1278e-02,  3.5678e-02, -6.2229e-03],\n",
       "                        [ 3.1843e-02, -9.5265e-02,  4.8114e-02],\n",
       "                        [-1.1036e-01, -6.9758e-02, -3.1029e-02],\n",
       "                        [ 2.0923e-02,  8.4046e-03,  6.0826e-02],\n",
       "                        [ 2.9969e-02,  8.9437e-02, -4.6374e-02],\n",
       "                        [-7.0824e-02,  1.2443e-01, -7.8701e-02],\n",
       "                        [-5.4597e-02, -1.0669e-01, -1.5869e-01],\n",
       "                        [-1.2929e-01,  7.7468e-02, -1.0734e-01],\n",
       "                        [-5.3259e-02, -8.2529e-02, -7.4156e-02],\n",
       "                        [-2.7846e-02, -5.9796e-03, -6.0808e-02],\n",
       "                        [-8.4703e-02, -4.3034e-02, -1.0619e-02],\n",
       "                        [-2.2842e-02,  2.1339e-01,  4.4372e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5438e-02,  9.0072e-02, -7.5919e-03],\n",
       "                        [-3.7212e-03, -7.5378e-02,  1.6196e-02],\n",
       "                        [ 1.7973e-03, -6.9698e-02, -6.0572e-03],\n",
       "                        [-4.0393e-02, -9.1330e-02, -3.1704e-02],\n",
       "                        [ 2.2080e-02, -4.3371e-02, -4.4038e-02],\n",
       "                        [-3.3314e-02, -5.4775e-02,  4.6427e-02],\n",
       "                        [-2.3978e-02,  3.9350e-02, -1.7408e-03],\n",
       "                        [-1.4299e-03,  9.1214e-02,  7.6740e-03],\n",
       "                        [ 1.4286e-01, -7.8007e-02, -5.3023e-02],\n",
       "                        [ 2.4837e-02, -6.6830e-04, -5.9182e-02],\n",
       "                        [-7.1316e-02,  2.2841e-02,  8.1599e-02],\n",
       "                        [ 2.5631e-02, -1.7065e-02,  9.0851e-02],\n",
       "                        [-3.5789e-02,  3.6820e-02, -3.9692e-02],\n",
       "                        [ 4.7035e-05,  6.6992e-02, -1.1758e-01],\n",
       "                        [ 2.1271e-03,  1.9587e-01, -1.4606e-01],\n",
       "                        [ 3.5899e-02,  3.2022e-01, -1.5919e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.6686e-02, -4.1231e-02,  1.8848e-02],\n",
       "                        [-1.4227e-02,  1.9205e-02, -5.5084e-02],\n",
       "                        [ 2.4228e-02, -8.0804e-02, -9.3563e-05],\n",
       "                        [-2.8529e-02, -8.4605e-02,  4.1722e-02],\n",
       "                        [ 4.8256e-03,  4.9330e-02, -8.5082e-02],\n",
       "                        [ 4.4759e-02,  1.2930e-02, -3.6418e-02],\n",
       "                        [ 7.0575e-02,  5.4303e-02, -4.9221e-02],\n",
       "                        [-6.4112e-02, -1.3341e-02,  2.7597e-02],\n",
       "                        [ 5.8464e-02,  5.3837e-03,  7.6931e-02],\n",
       "                        [-6.8201e-03,  8.7491e-02, -5.7355e-02],\n",
       "                        [-6.2826e-03,  7.3556e-02,  4.0002e-02],\n",
       "                        [-4.9298e-02, -1.5169e-02,  6.5847e-02],\n",
       "                        [ 8.5297e-02, -9.4833e-02, -3.6334e-02],\n",
       "                        [-7.7673e-02, -8.2518e-02, -3.0828e-02],\n",
       "                        [-1.3485e-01,  3.9571e-02,  1.0585e-01],\n",
       "                        [-6.9047e-02,  6.5985e-02,  3.7733e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6027e-03,  4.0546e-02,  3.6602e-02],\n",
       "                        [ 5.1214e-02,  3.1059e-02, -5.9840e-02],\n",
       "                        [ 3.9005e-02,  5.1756e-02,  4.4526e-02],\n",
       "                        [-1.2723e-02,  1.9004e-02, -3.0953e-02],\n",
       "                        [-1.6002e-02, -4.1025e-02,  5.1181e-02],\n",
       "                        [ 5.8616e-02, -6.1388e-02,  5.8451e-02],\n",
       "                        [-2.5799e-02, -1.0343e-01,  8.9262e-02],\n",
       "                        [-1.3763e-02,  1.3807e-01, -9.1607e-02],\n",
       "                        [-8.0168e-02, -3.2341e-02, -2.5406e-02],\n",
       "                        [ 2.3977e-02, -6.8154e-02,  1.7676e-01],\n",
       "                        [-1.5661e-01, -2.2265e-02, -1.0118e-01],\n",
       "                        [-5.7798e-02, -5.2294e-02, -2.6452e-02],\n",
       "                        [-5.0351e-02,  9.9140e-02, -1.6966e-02],\n",
       "                        [-6.4883e-02,  1.0599e-01,  1.3544e-02],\n",
       "                        [-3.0780e-02,  1.3789e-01, -3.0020e-02],\n",
       "                        [-2.6525e-02,  8.6215e-02, -1.1621e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.2397e-02, -8.2354e-02,  5.7852e-02],\n",
       "                        [-1.8839e-02,  3.2878e-02, -1.4064e-01],\n",
       "                        [-2.8671e-02, -3.6064e-02, -4.0630e-02],\n",
       "                        [-6.8466e-02,  3.5944e-03, -8.7186e-02],\n",
       "                        [-9.4213e-03,  2.0132e-02, -2.0190e-02],\n",
       "                        [ 1.1092e-02,  1.3176e-02, -9.9505e-02],\n",
       "                        [-2.4436e-02, -1.5572e-02, -6.6864e-02],\n",
       "                        [-7.3323e-02,  2.6945e-02, -7.9694e-02],\n",
       "                        [-5.0702e-02,  2.4202e-02,  6.3083e-04],\n",
       "                        [ 4.7084e-02,  8.1624e-02, -1.1267e-01],\n",
       "                        [-2.2481e-02,  1.0422e-01, -1.1279e-01],\n",
       "                        [ 4.5967e-02, -5.4065e-02,  1.7772e-02],\n",
       "                        [ 6.5438e-02,  4.7285e-02, -3.7405e-02],\n",
       "                        [-2.5223e-02,  1.4416e-01, -1.2054e-01],\n",
       "                        [ 6.8800e-02,  4.5307e-02, -1.4481e-01],\n",
       "                        [-8.2716e-03,  2.2316e-01, -2.0495e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7757e-02,  4.5310e-02,  7.4250e-02],\n",
       "                        [-7.4802e-02, -4.2679e-02, -5.6695e-02],\n",
       "                        [ 4.1116e-02, -8.5184e-02,  1.7559e-02],\n",
       "                        [-6.6750e-03,  7.0161e-02, -3.0459e-02],\n",
       "                        [ 5.0472e-02, -1.6741e-02,  1.3230e-02],\n",
       "                        [-8.6498e-02,  8.2776e-02,  2.6947e-02],\n",
       "                        [ 3.3340e-02, -5.4769e-02, -3.4368e-02],\n",
       "                        [ 4.1967e-02,  6.9763e-02,  9.1743e-03],\n",
       "                        [ 7.3196e-02, -8.4905e-02, -4.0363e-02],\n",
       "                        [ 4.4436e-04,  2.5249e-02,  2.7168e-02],\n",
       "                        [-4.3395e-02,  1.0794e-01,  2.3647e-02],\n",
       "                        [-3.5413e-02, -6.7610e-02, -2.2448e-02],\n",
       "                        [-1.7414e-02, -9.6522e-02,  4.1064e-02],\n",
       "                        [ 1.0748e-01, -5.7127e-03, -8.0582e-03],\n",
       "                        [ 1.0768e-01, -1.6263e-01,  1.5770e-01],\n",
       "                        [ 5.0640e-02, -2.1925e-01,  9.6678e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7684e-03,  6.3578e-02,  4.8070e-02],\n",
       "                        [-1.0743e-02,  7.4254e-02,  4.2473e-02],\n",
       "                        [-6.9171e-02,  9.5457e-03,  2.0411e-02],\n",
       "                        [ 7.4817e-03,  5.2923e-04, -1.0478e-02],\n",
       "                        [ 4.7432e-02,  8.5432e-02, -2.6137e-02],\n",
       "                        [ 8.3665e-02, -6.9902e-02,  1.9120e-03],\n",
       "                        [ 1.9294e-02, -7.0109e-02,  7.3412e-02],\n",
       "                        [-7.1188e-02,  3.8452e-02, -1.2061e-01],\n",
       "                        [ 2.4961e-02, -9.6769e-02,  6.7735e-02],\n",
       "                        [ 5.8211e-02,  7.6164e-02, -9.0351e-02],\n",
       "                        [ 3.8900e-02,  4.2763e-02, -6.7825e-02],\n",
       "                        [ 1.8831e-02,  9.3048e-02,  1.0271e-01],\n",
       "                        [ 6.5445e-02, -7.0828e-02, -3.7124e-03],\n",
       "                        [-4.1637e-02, -1.5440e-02, -8.1657e-03],\n",
       "                        [-7.4774e-02, -6.2639e-02,  1.5336e-01],\n",
       "                        [-3.1442e-02,  7.7207e-02,  2.2683e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5842e-02, -1.4569e-01, -5.0915e-02],\n",
       "                        [ 7.6683e-02, -6.6628e-02,  1.0635e-01],\n",
       "                        [ 1.2113e-02,  1.3676e-02,  2.6430e-02],\n",
       "                        [-1.5511e-02, -4.1807e-02,  9.8672e-02],\n",
       "                        [ 2.1669e-02,  6.0852e-02, -1.6787e-02],\n",
       "                        [-4.5657e-02,  5.8097e-02,  5.8663e-03],\n",
       "                        [-3.0662e-02,  6.6977e-02, -5.6178e-02],\n",
       "                        [-9.7700e-02, -1.8613e-02, -6.6332e-02],\n",
       "                        [-3.6616e-02,  3.6572e-02, -1.7959e-02],\n",
       "                        [ 5.2096e-02, -8.2766e-02,  6.7720e-02],\n",
       "                        [ 5.3912e-02, -1.3075e-01, -7.0127e-02],\n",
       "                        [ 5.0321e-02,  7.2414e-03, -5.8098e-02],\n",
       "                        [ 5.8269e-02,  8.1823e-02, -4.6193e-02],\n",
       "                        [-1.2876e-02,  5.4448e-02, -5.2584e-02],\n",
       "                        [-8.3309e-02,  6.6508e-02, -3.2031e-02],\n",
       "                        [-9.6039e-02, -1.1809e-02, -6.3919e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7450e-02, -3.6985e-02, -4.1943e-02],\n",
       "                        [ 7.3293e-02, -1.4598e-03,  3.1142e-02],\n",
       "                        [ 6.0834e-02,  4.7800e-02,  1.1522e-01],\n",
       "                        [ 3.9288e-02, -5.6567e-02, -6.5723e-02],\n",
       "                        [ 3.1296e-03, -2.5505e-02,  2.9408e-02],\n",
       "                        [ 2.4978e-02, -9.3325e-02, -4.2299e-02],\n",
       "                        [-4.4294e-02,  1.1218e-02,  2.0864e-02],\n",
       "                        [ 6.4887e-02, -8.7553e-02, -4.5076e-02],\n",
       "                        [-6.7815e-02,  4.5252e-02,  4.5672e-02],\n",
       "                        [-3.1748e-02,  9.3225e-02,  8.2712e-02],\n",
       "                        [ 2.5185e-02, -3.4516e-02,  1.1660e-01],\n",
       "                        [ 9.2442e-02,  6.1538e-02,  8.9857e-02],\n",
       "                        [ 8.0162e-02,  4.8418e-02, -1.3220e-01],\n",
       "                        [ 6.0181e-03,  9.8602e-02, -1.3894e-01],\n",
       "                        [ 2.2759e-02,  1.3651e-01, -6.2721e-02],\n",
       "                        [-2.4505e-02,  4.3486e-02, -1.0261e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1477e-02, -7.3395e-02, -3.5340e-02],\n",
       "                        [ 6.8142e-02, -8.0937e-02,  1.1382e-01],\n",
       "                        [ 2.6708e-02, -1.7881e-02,  5.1717e-05],\n",
       "                        [-2.9821e-02,  8.4614e-02, -2.4964e-02],\n",
       "                        [-7.5390e-02, -7.4930e-02,  7.0059e-02],\n",
       "                        [ 3.6532e-02, -7.4735e-02,  2.9489e-02],\n",
       "                        [ 5.5028e-02, -4.6852e-02,  1.1944e-02],\n",
       "                        [-1.1141e-02, -1.1603e-01, -6.9883e-02],\n",
       "                        [ 2.2311e-02, -2.8804e-02,  2.0751e-02],\n",
       "                        [ 1.4870e-01, -2.2351e-01, -6.4499e-02],\n",
       "                        [ 2.3435e-03, -2.1129e-01,  4.7008e-02],\n",
       "                        [-4.6069e-02, -7.0899e-02,  6.2928e-02],\n",
       "                        [-1.9343e-02, -4.7609e-02,  1.2191e-01],\n",
       "                        [-5.9350e-02, -1.6330e-01,  3.8049e-02],\n",
       "                        [ 9.7122e-02, -6.6283e-02,  1.3089e-01],\n",
       "                        [ 3.8323e-02,  6.8973e-02,  1.6620e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.3459e-02,  2.6289e-02,  6.7754e-03],\n",
       "                        [-4.4383e-02, -8.7000e-03,  4.2847e-02],\n",
       "                        [ 3.2985e-02,  2.7011e-02, -1.6896e-02],\n",
       "                        [-9.5243e-03,  5.7682e-02,  6.0633e-02],\n",
       "                        [ 2.6412e-02,  1.4338e-02, -3.0929e-02],\n",
       "                        [ 1.7173e-02,  2.7498e-02, -6.7209e-02],\n",
       "                        [-3.4072e-02,  1.6552e-02,  6.0181e-02],\n",
       "                        [-5.9901e-02,  2.8924e-02, -2.5635e-02],\n",
       "                        [-3.8145e-02,  5.8685e-02,  6.2973e-02],\n",
       "                        [-9.0056e-02,  6.0057e-02,  4.7921e-02],\n",
       "                        [-7.3961e-02,  4.7503e-02,  3.2043e-02],\n",
       "                        [ 4.0300e-02, -9.4409e-03,  1.9933e-02],\n",
       "                        [ 3.1644e-02,  6.2582e-02,  9.0029e-02],\n",
       "                        [ 1.1421e-01,  1.8079e-02, -6.1815e-03],\n",
       "                        [-2.2675e-02, -9.1507e-02,  8.5147e-02],\n",
       "                        [ 2.9241e-02, -1.3512e-01, -1.4012e-01]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 0.0159,  0.0222,  0.0208, -0.0018, -0.0106, -0.0070,  0.0136, -0.0119,\n",
       "                       0.0137, -0.0071,  0.0053,  0.0061,  0.0241, -0.0320, -0.0195, -0.0567])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-2.0555e-02,  9.7138e-02, -4.0848e-02, -1.2037e-01,  3.7162e-02],\n",
       "                        [ 1.2499e-02, -5.2797e-02, -7.8334e-02,  9.2560e-05,  5.8663e-02],\n",
       "                        [-6.3088e-02, -7.6075e-02, -3.7707e-02,  7.0113e-02, -3.6431e-02]],\n",
       "              \n",
       "                       [[-5.0902e-03, -7.2265e-02,  7.6855e-02, -7.8465e-02,  1.3935e-02],\n",
       "                        [ 3.5243e-02, -6.0829e-02, -6.7080e-02, -1.8435e-01, -1.2000e-01],\n",
       "                        [-6.1129e-02, -2.8671e-02,  5.9991e-02,  3.1059e-02,  1.4411e-02]],\n",
       "              \n",
       "                       [[-3.1553e-02,  5.2054e-02,  7.8080e-02, -4.0770e-02,  4.1174e-02],\n",
       "                        [-4.7762e-02, -1.7915e-02,  3.0051e-02, -8.0849e-02,  3.4968e-03],\n",
       "                        [-7.3102e-02,  7.3820e-02,  8.5199e-02, -1.1456e-01,  1.8990e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.4116e-02, -1.2719e-01, -3.3665e-02,  3.7353e-02,  7.6065e-02],\n",
       "                        [-1.3939e-01, -5.3443e-02,  2.3546e-02,  4.8591e-02, -1.0426e-03],\n",
       "                        [-1.0222e-01, -1.4926e-02, -4.1745e-02, -1.7447e-02, -3.0388e-02]],\n",
       "              \n",
       "                       [[-3.8560e-02, -8.7067e-02,  5.2374e-03,  1.1967e-01, -1.1883e-01],\n",
       "                        [ 1.1792e-01,  8.3752e-02,  8.7342e-02,  2.1760e-02, -5.8630e-02],\n",
       "                        [-8.4128e-03,  3.8416e-02, -3.8059e-02,  4.2540e-03,  4.1360e-02]],\n",
       "              \n",
       "                       [[-8.9916e-03, -9.2058e-02, -1.9676e-02, -8.2352e-02,  9.9289e-02],\n",
       "                        [-9.4182e-02,  7.1038e-02,  6.3545e-02,  6.2749e-03,  2.2332e-02],\n",
       "                        [-2.0960e-03,  3.8861e-02, -9.8535e-02,  1.0182e-01,  7.9994e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.2360e-03,  8.9495e-03,  6.5929e-02, -3.6912e-02,  4.3589e-02],\n",
       "                        [ 1.1577e-01, -3.8348e-02, -3.7641e-02,  1.5223e-01, -6.5964e-02],\n",
       "                        [-4.8101e-02, -7.5327e-02,  7.0348e-02,  1.1293e-01, -8.9120e-02]],\n",
       "              \n",
       "                       [[-2.0696e-02,  5.4046e-02, -1.5192e-01,  3.4034e-02, -8.5130e-02],\n",
       "                        [-5.0403e-02, -4.2222e-02, -2.7760e-03, -1.4016e-01, -2.4686e-02],\n",
       "                        [ 1.2589e-02, -1.5113e-03,  1.5784e-02,  7.0369e-03,  1.8476e-02]],\n",
       "              \n",
       "                       [[-3.9701e-02,  8.5597e-02, -4.8969e-02,  1.2785e-02,  1.7199e-01],\n",
       "                        [ 1.0621e-01, -2.9584e-02, -7.0905e-02, -2.8875e-02,  9.1206e-02],\n",
       "                        [ 8.9887e-02,  7.1726e-02,  3.5794e-03, -6.3389e-02,  8.2749e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.4708e-02,  4.2481e-02,  1.9822e-03, -9.9056e-03, -1.2757e-01],\n",
       "                        [ 7.7762e-02, -1.0050e-01, -1.1283e-01, -7.2030e-04, -6.3486e-04],\n",
       "                        [ 5.4205e-02,  5.3024e-02, -2.1321e-02,  5.5143e-03, -3.5650e-02]],\n",
       "              \n",
       "                       [[-2.9976e-02,  8.0141e-03,  2.2653e-02,  8.3635e-02, -8.0533e-03],\n",
       "                        [ 4.2352e-02, -9.8123e-02, -8.9004e-02, -5.9104e-02, -3.0008e-02],\n",
       "                        [-6.7825e-02, -7.2254e-02,  9.3141e-02,  1.2524e-01, -1.3537e-01]],\n",
       "              \n",
       "                       [[-2.9536e-03, -1.8903e-02, -1.0609e-03,  3.8172e-02, -5.4986e-02],\n",
       "                        [-8.3031e-02, -1.1740e-01, -8.0441e-02, -1.9587e-02,  1.0940e-02],\n",
       "                        [ 3.8597e-02, -3.4584e-02, -1.7205e-01, -6.1714e-02,  8.2565e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0984e-02, -2.0896e-02,  7.8720e-02,  4.1834e-02, -9.1859e-02],\n",
       "                        [ 6.1151e-02, -1.0341e-01,  1.0732e-01, -4.8923e-02, -4.6347e-02],\n",
       "                        [-5.2679e-02,  6.3326e-02, -1.4639e-01,  8.3718e-02, -1.1636e-01]],\n",
       "              \n",
       "                       [[-5.8496e-02, -3.3417e-02,  5.5762e-02, -2.3044e-02,  1.6830e-02],\n",
       "                        [ 9.7956e-02, -5.1957e-03,  2.9546e-02,  2.8515e-02,  2.4973e-02],\n",
       "                        [-1.3747e-01, -9.2128e-02, -1.9750e-02, -8.4445e-02, -1.1162e-01]],\n",
       "              \n",
       "                       [[ 1.9559e-01,  3.3649e-02, -4.6045e-02, -3.9558e-02, -1.6916e-02],\n",
       "                        [-3.7971e-02,  6.2866e-02,  1.3431e-01, -4.2281e-02, -6.4502e-02],\n",
       "                        [ 2.8611e-02, -8.3514e-03, -7.0000e-02, -1.0101e-01, -1.2516e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.6311e-02,  2.8861e-02,  1.4329e-01, -6.6641e-02, -3.8952e-02],\n",
       "                        [ 9.8183e-02,  2.9647e-02,  7.9123e-02, -2.3757e-02,  2.4161e-02],\n",
       "                        [-1.3256e-02, -2.1480e-03, -6.9156e-02,  8.5666e-02, -1.1012e-01]],\n",
       "              \n",
       "                       [[-5.5288e-02, -4.2684e-02,  1.8081e-02, -1.1699e-01,  6.1068e-02],\n",
       "                        [ 3.6555e-02,  6.5248e-02,  7.6652e-02, -1.4211e-01, -2.0800e-02],\n",
       "                        [-1.5975e-01, -9.1559e-04,  6.3590e-02,  1.1833e-01, -4.1456e-03]],\n",
       "              \n",
       "                       [[ 3.0025e-02,  9.9763e-02, -5.8520e-02, -2.7599e-02,  5.6014e-02],\n",
       "                        [-8.4837e-02, -1.8280e-02, -2.3200e-02, -6.3168e-02, -9.8759e-02],\n",
       "                        [ 7.3012e-02,  5.6826e-02,  1.1163e-01, -3.7141e-02,  4.5515e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 5.3935e-02,  6.0227e-02, -6.1386e-02, -6.2350e-02, -3.6074e-02],\n",
       "                        [-1.0237e-01,  2.3451e-02, -1.7344e-02,  2.3501e-02,  9.5381e-02],\n",
       "                        [-9.0189e-02, -2.3463e-02, -7.5570e-03, -6.6011e-02, -1.0446e-01]],\n",
       "              \n",
       "                       [[ 6.9988e-03, -1.0773e-01, -5.3788e-02, -6.8181e-02, -1.0620e-01],\n",
       "                        [ 8.4196e-02, -2.3225e-02, -9.1933e-02, -1.0012e-01,  1.0021e-01],\n",
       "                        [-5.9101e-02, -5.0812e-02, -3.0492e-02, -9.1048e-02, -6.9750e-02]],\n",
       "              \n",
       "                       [[-6.5959e-02,  1.0294e-01, -6.9291e-02, -9.5244e-03,  1.0840e-01],\n",
       "                        [-1.4834e-01,  1.0043e-02,  5.5378e-02,  1.4561e-02, -2.3521e-02],\n",
       "                        [-1.4187e-02,  6.8181e-02,  5.3632e-02,  1.6100e-02, -8.7599e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.2684e-02,  3.3490e-02,  1.1809e-01, -7.5068e-02,  9.0558e-02],\n",
       "                        [ 2.3710e-02, -3.4856e-02, -5.5889e-02,  9.7618e-02, -1.0842e-02],\n",
       "                        [ 5.3876e-02, -8.5941e-03,  7.9137e-02, -1.2307e-01,  1.0004e-01]],\n",
       "              \n",
       "                       [[-4.1381e-03, -7.3619e-02,  8.2364e-02, -1.8239e-03,  1.2355e-01],\n",
       "                        [-3.1423e-03, -1.5081e-02,  1.1308e-02,  1.0289e-01, -6.5928e-02],\n",
       "                        [-7.2668e-02, -1.1053e-01,  9.6941e-02, -4.8790e-02, -5.4439e-02]],\n",
       "              \n",
       "                       [[ 2.6720e-02,  1.2180e-01, -6.8582e-02,  6.1255e-02, -5.1927e-02],\n",
       "                        [-7.3986e-02, -2.5213e-02, -6.7025e-02,  2.6358e-02, -1.0384e-01],\n",
       "                        [ 6.7859e-02, -9.4301e-02, -3.4462e-02,  5.8097e-02, -7.8577e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.6535e-02,  1.2407e-01, -2.4642e-02,  7.6370e-02, -4.5243e-02],\n",
       "                        [ 4.0157e-02, -1.0899e-01,  3.7241e-02, -7.8735e-02,  9.0305e-02],\n",
       "                        [ 4.7590e-02, -4.1738e-02,  3.0535e-03, -6.4438e-02, -1.6763e-02]],\n",
       "              \n",
       "                       [[-1.0080e-01,  8.4304e-03, -9.5840e-03,  8.5388e-02, -1.1752e-01],\n",
       "                        [-1.1415e-02, -7.9178e-02,  4.2129e-03,  1.1672e-01,  6.9978e-02],\n",
       "                        [ 4.9630e-03,  5.3751e-02,  7.5360e-02,  1.2053e-01, -3.1503e-02]],\n",
       "              \n",
       "                       [[-4.0117e-02,  3.6043e-02,  1.1828e-01,  5.8458e-02, -4.6059e-03],\n",
       "                        [-1.0329e-01, -2.1480e-02, -2.5674e-02,  1.7379e-01, -9.8792e-02],\n",
       "                        [-9.7358e-02,  1.4361e-02,  1.1448e-01,  7.9423e-02, -1.6025e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.1812e-03,  9.7586e-02, -2.5741e-02, -5.2646e-02,  6.6657e-02],\n",
       "                        [-1.1117e-01, -1.0416e-01, -3.6352e-02, -2.4982e-02,  5.4644e-02],\n",
       "                        [-2.8759e-02, -1.3303e-01,  1.0332e-01,  4.3398e-02,  7.8179e-02]],\n",
       "              \n",
       "                       [[-1.0036e-01, -3.0175e-02,  9.1563e-02,  3.6617e-02,  8.8039e-02],\n",
       "                        [ 1.0512e-01,  1.2005e-01, -3.5403e-02, -2.5552e-03, -4.2478e-02],\n",
       "                        [ 6.0518e-02,  1.5488e-01, -4.5996e-02, -3.7246e-02,  8.2269e-02]],\n",
       "              \n",
       "                       [[-1.9820e-02, -1.5266e-01, -6.3428e-02, -6.8677e-02, -8.1998e-02],\n",
       "                        [-2.4589e-02, -6.4255e-02, -1.0608e-01, -1.0404e-01,  1.5949e-02],\n",
       "                        [-2.1209e-02, -8.6275e-02,  9.8081e-02,  6.9879e-02, -2.0808e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.9329e-02,  7.1450e-02,  9.6822e-02,  1.1316e-01,  7.4148e-02],\n",
       "                        [ 1.3226e-01,  5.0796e-02,  5.7468e-02,  9.2399e-02,  9.0806e-03],\n",
       "                        [-3.3745e-02,  1.2450e-01, -1.2528e-01, -2.7824e-02, -6.1171e-02]],\n",
       "              \n",
       "                       [[-2.6402e-04, -3.8944e-02,  6.2310e-02, -6.6092e-02,  3.4456e-02],\n",
       "                        [ 7.1150e-02, -9.6465e-02,  1.2003e-01,  2.4486e-02, -8.9977e-02],\n",
       "                        [-6.4489e-02, -9.8971e-02,  2.7729e-02, -1.3404e-01, -9.3966e-02]],\n",
       "              \n",
       "                       [[-1.2071e-04, -6.5916e-02,  1.4008e-01,  4.3204e-02,  4.8634e-02],\n",
       "                        [-1.5647e-01,  4.6984e-02,  9.6823e-03, -8.8045e-02, -3.0005e-02],\n",
       "                        [ 5.6580e-02,  1.0890e-01,  8.8901e-03,  7.5028e-02, -2.3535e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.3028e-02, -1.1251e-01, -2.6558e-02, -9.7483e-02,  1.0746e-01],\n",
       "                        [ 7.8746e-02,  9.0059e-02, -3.0778e-02,  7.8617e-02, -9.3068e-02],\n",
       "                        [ 1.2334e-01,  1.2472e-01, -9.7778e-02, -3.9292e-02, -3.7072e-02]],\n",
       "              \n",
       "                       [[ 4.9964e-02, -2.3414e-03, -8.7910e-02,  2.6236e-02, -3.4842e-03],\n",
       "                        [-5.9054e-02,  9.5696e-02,  3.3416e-03, -6.6162e-02,  7.8993e-02],\n",
       "                        [-1.2907e-01,  1.0495e-01,  3.2580e-03,  1.0245e-01, -1.5208e-01]],\n",
       "              \n",
       "                       [[-2.7130e-02,  1.3537e-01,  1.1858e-01, -4.8490e-02,  8.0646e-02],\n",
       "                        [-1.0127e-01, -1.8060e-02,  7.7232e-02,  4.6883e-02,  9.4005e-02],\n",
       "                        [-4.6845e-02, -1.2219e-02, -4.5225e-02, -6.2755e-02,  4.5546e-02]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.0069,  0.0057, -0.0091,  0.0139,  0.0031,  0.0009, -0.0077, -0.0102,\n",
       "                      -0.0022, -0.0122, -0.0036, -0.0256,  0.0172, -0.0037,  0.0350, -0.0047])),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[ 0.0945,  0.0743,  0.0344],\n",
       "                        [ 0.0462, -0.0908, -0.0602],\n",
       "                        [ 0.1215, -0.0119, -0.0660],\n",
       "                        [-0.0722, -0.0881, -0.0982]],\n",
       "              \n",
       "                       [[-0.0620, -0.0003, -0.0675],\n",
       "                        [ 0.0875, -0.0491, -0.0369],\n",
       "                        [ 0.1135,  0.0070, -0.0279],\n",
       "                        [ 0.0340, -0.1091,  0.0783]],\n",
       "              \n",
       "                       [[-0.0298, -0.0207,  0.0808],\n",
       "                        [ 0.0304,  0.0167, -0.0210],\n",
       "                        [ 0.0659, -0.1156, -0.0833],\n",
       "                        [-0.0998, -0.1550,  0.0445]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0079, -0.0380,  0.0787],\n",
       "                        [ 0.0730,  0.0536,  0.0690],\n",
       "                        [-0.1139, -0.1036, -0.0609],\n",
       "                        [-0.0713, -0.0332,  0.0590]],\n",
       "              \n",
       "                       [[-0.0524, -0.0497, -0.1841],\n",
       "                        [-0.0852,  0.0771, -0.1404],\n",
       "                        [-0.0573, -0.0216, -0.2154],\n",
       "                        [-0.0188, -0.0400, -0.0023]],\n",
       "              \n",
       "                       [[-0.0943,  0.0009,  0.0719],\n",
       "                        [-0.0649,  0.0896, -0.0674],\n",
       "                        [ 0.1007,  0.0472, -0.1437],\n",
       "                        [ 0.0588, -0.0565,  0.0729]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0622,  0.0331, -0.1067],\n",
       "                        [ 0.0544, -0.1010,  0.0203],\n",
       "                        [-0.0265, -0.0704,  0.0234],\n",
       "                        [ 0.0620,  0.0522, -0.0300]],\n",
       "              \n",
       "                       [[-0.0934,  0.0409, -0.1063],\n",
       "                        [-0.0909, -0.0779,  0.0414],\n",
       "                        [-0.0349, -0.0531, -0.0031],\n",
       "                        [ 0.0726, -0.1090, -0.0643]],\n",
       "              \n",
       "                       [[ 0.0140, -0.0102, -0.0787],\n",
       "                        [ 0.0272,  0.0387, -0.0460],\n",
       "                        [ 0.0649, -0.1204, -0.0130],\n",
       "                        [-0.0360, -0.0678,  0.0151]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0441, -0.0403, -0.0734],\n",
       "                        [-0.0472, -0.0631, -0.0426],\n",
       "                        [-0.0270,  0.0522,  0.0333],\n",
       "                        [-0.0664,  0.0331, -0.0381]],\n",
       "              \n",
       "                       [[-0.1038, -0.0563, -0.0932],\n",
       "                        [ 0.0104, -0.1156, -0.0587],\n",
       "                        [ 0.0115, -0.0750, -0.0348],\n",
       "                        [-0.0962,  0.0309, -0.0571]],\n",
       "              \n",
       "                       [[ 0.0841, -0.0140,  0.0269],\n",
       "                        [-0.0591, -0.1093,  0.0355],\n",
       "                        [-0.0537,  0.0760,  0.0449],\n",
       "                        [ 0.0064, -0.0559, -0.0833]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0022,  0.0697, -0.0854],\n",
       "                        [ 0.0837, -0.0062,  0.0567],\n",
       "                        [-0.0513, -0.0548, -0.0310],\n",
       "                        [ 0.0079,  0.0694,  0.0891]],\n",
       "              \n",
       "                       [[-0.0561, -0.0650, -0.0081],\n",
       "                        [-0.0577,  0.0434,  0.0292],\n",
       "                        [ 0.1024,  0.0428,  0.0577],\n",
       "                        [-0.0574,  0.0873,  0.0289]],\n",
       "              \n",
       "                       [[-0.0301,  0.0357,  0.0933],\n",
       "                        [-0.0698,  0.0351, -0.0221],\n",
       "                        [-0.0654,  0.0781,  0.0504],\n",
       "                        [-0.0003,  0.0325, -0.0205]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0028,  0.0678, -0.0185],\n",
       "                        [-0.1142,  0.0947,  0.0112],\n",
       "                        [-0.0399,  0.0322,  0.0349],\n",
       "                        [ 0.0289, -0.1106,  0.0532]],\n",
       "              \n",
       "                       [[-0.0519, -0.0027,  0.0658],\n",
       "                        [ 0.0141,  0.0447, -0.0315],\n",
       "                        [ 0.0870, -0.0178,  0.0475],\n",
       "                        [-0.0613,  0.0287, -0.1007]],\n",
       "              \n",
       "                       [[-0.0142,  0.0548,  0.0085],\n",
       "                        [ 0.0104, -0.0196,  0.0050],\n",
       "                        [-0.1012,  0.0540, -0.1092],\n",
       "                        [-0.0297,  0.1311, -0.0850]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.1021, -0.1104,  0.1339],\n",
       "                        [-0.0643, -0.0608,  0.0225],\n",
       "                        [-0.1164,  0.0036,  0.0127],\n",
       "                        [-0.1149,  0.0366, -0.1005]],\n",
       "              \n",
       "                       [[ 0.0527,  0.1051,  0.0089],\n",
       "                        [-0.0922, -0.0780, -0.0176],\n",
       "                        [ 0.0910, -0.0823, -0.1678],\n",
       "                        [ 0.0161, -0.0321, -0.1618]],\n",
       "              \n",
       "                       [[-0.0053,  0.0071,  0.0639],\n",
       "                        [-0.1186,  0.0288,  0.0105],\n",
       "                        [ 0.0402, -0.0767, -0.0337],\n",
       "                        [-0.0881, -0.1280,  0.0815]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0728,  0.0350, -0.1110],\n",
       "                        [ 0.0517,  0.0394,  0.0335],\n",
       "                        [ 0.0979,  0.0609, -0.1114],\n",
       "                        [ 0.0916, -0.0247,  0.0362]],\n",
       "              \n",
       "                       [[ 0.0372,  0.0132,  0.0937],\n",
       "                        [ 0.0618,  0.0859,  0.0551],\n",
       "                        [ 0.0327,  0.1243, -0.0597],\n",
       "                        [-0.0200,  0.0107,  0.0676]],\n",
       "              \n",
       "                       [[-0.0513, -0.0811, -0.0651],\n",
       "                        [-0.0838, -0.1273,  0.1201],\n",
       "                        [ 0.0163, -0.0546,  0.0394],\n",
       "                        [ 0.0157, -0.0857, -0.0035]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0319,  0.0108,  0.0020],\n",
       "                        [ 0.0220, -0.1649, -0.1032],\n",
       "                        [-0.0782,  0.0108, -0.0137],\n",
       "                        [-0.0902,  0.1104, -0.0590]],\n",
       "              \n",
       "                       [[ 0.0859, -0.0822,  0.0398],\n",
       "                        [-0.0013, -0.0049, -0.0805],\n",
       "                        [-0.0002,  0.1184, -0.0464],\n",
       "                        [-0.0218,  0.0152, -0.0797]],\n",
       "              \n",
       "                       [[ 0.0549,  0.0764, -0.1031],\n",
       "                        [-0.0322,  0.0373, -0.1061],\n",
       "                        [ 0.0831,  0.0609,  0.0188],\n",
       "                        [ 0.0748,  0.0764, -0.0740]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0791,  0.0170,  0.0252],\n",
       "                        [-0.0632, -0.1095, -0.0044],\n",
       "                        [ 0.0629, -0.0810, -0.0177],\n",
       "                        [ 0.0136, -0.0762, -0.0206]],\n",
       "              \n",
       "                       [[-0.0597,  0.0515,  0.1024],\n",
       "                        [ 0.0317,  0.0554, -0.1373],\n",
       "                        [ 0.0852, -0.1310, -0.1345],\n",
       "                        [-0.0627, -0.1207, -0.0423]],\n",
       "              \n",
       "                       [[-0.0406,  0.0904,  0.0007],\n",
       "                        [-0.0551, -0.0474,  0.0411],\n",
       "                        [ 0.0793, -0.0531,  0.0872],\n",
       "                        [-0.0455,  0.0815, -0.1016]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0461,  0.1517, -0.0042],\n",
       "                        [-0.0092, -0.0637, -0.0636],\n",
       "                        [-0.0920, -0.0550,  0.0513],\n",
       "                        [ 0.0526,  0.0016, -0.0488]],\n",
       "              \n",
       "                       [[-0.0375, -0.0585, -0.0567],\n",
       "                        [ 0.1076,  0.0345, -0.0475],\n",
       "                        [-0.0897, -0.0348,  0.0246],\n",
       "                        [-0.0740,  0.0396, -0.0229]],\n",
       "              \n",
       "                       [[ 0.0633, -0.0362, -0.0623],\n",
       "                        [ 0.0354, -0.0440,  0.0100],\n",
       "                        [-0.0947,  0.0498, -0.0385],\n",
       "                        [ 0.0272,  0.0628,  0.0059]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0975,  0.1060,  0.1187],\n",
       "                        [ 0.0031, -0.0260, -0.0580],\n",
       "                        [ 0.0220, -0.0268, -0.0114],\n",
       "                        [ 0.0580, -0.0649, -0.0073]],\n",
       "              \n",
       "                       [[ 0.0802,  0.0554, -0.1000],\n",
       "                        [ 0.0600, -0.1255, -0.0144],\n",
       "                        [-0.0776,  0.0459,  0.0451],\n",
       "                        [-0.1797, -0.1123, -0.1385]],\n",
       "              \n",
       "                       [[ 0.1472,  0.0655,  0.0762],\n",
       "                        [-0.0631, -0.1226, -0.0036],\n",
       "                        [ 0.0172, -0.1050,  0.0503],\n",
       "                        [-0.0941,  0.0220,  0.0641]]]])),\n",
       "             ('conv3.bias',\n",
       "              tensor([ 1.4367e-02, -2.8126e-02, -3.6829e-03,  2.2941e-03,  7.4266e-05,\n",
       "                      -1.8703e-02,  1.4539e-03, -3.5988e-02,  1.5714e-02, -8.3564e-04,\n",
       "                      -5.3293e-03, -5.0351e-02, -3.9801e-03, -1.1310e-02, -1.3735e-02,\n",
       "                      -1.1188e-02,  3.4839e-03,  6.4877e-03, -4.3286e-03,  2.0033e-02,\n",
       "                      -4.5845e-03,  1.2852e-03, -1.5038e-02, -6.0721e-03, -8.2661e-03,\n",
       "                      -3.2868e-02, -1.3114e-02, -2.6365e-03, -4.3474e-02, -1.2026e-02,\n",
       "                      -2.5832e-03,  9.3449e-04])),\n",
       "             ('conv4.weight',\n",
       "              tensor([[[[-6.0154e-02, -2.1229e-02, -1.5306e-01],\n",
       "                        [ 5.1914e-02,  3.4432e-02, -9.4434e-02],\n",
       "                        [-5.7798e-02,  1.1698e-01, -1.1812e-01],\n",
       "                        [-6.0401e-02,  1.5012e-02, -6.2421e-03]],\n",
       "              \n",
       "                       [[ 3.9114e-02,  6.5113e-02, -3.4216e-02],\n",
       "                        [ 8.9774e-02,  3.4896e-02,  6.2300e-02],\n",
       "                        [-1.2539e-03,  6.9578e-02, -4.2725e-02],\n",
       "                        [ 2.8374e-02,  3.9999e-02,  4.6738e-03]],\n",
       "              \n",
       "                       [[-5.5941e-02,  1.5274e-02,  8.1047e-02],\n",
       "                        [-6.0067e-02,  5.6427e-02,  2.4907e-02],\n",
       "                        [-4.1381e-02,  8.2256e-02,  4.8608e-02],\n",
       "                        [-6.6908e-02, -3.4642e-02,  3.5736e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.2941e-02, -1.3665e-01,  2.1483e-02],\n",
       "                        [ 4.0806e-02,  3.6491e-02, -1.4010e-01],\n",
       "                        [ 6.6406e-02,  4.3674e-02, -1.3494e-01],\n",
       "                        [ 6.0006e-02,  8.0835e-02,  2.6919e-02]],\n",
       "              \n",
       "                       [[-3.8562e-02,  4.5415e-02,  1.1438e-01],\n",
       "                        [-7.6415e-02,  6.3750e-02, -9.4428e-02],\n",
       "                        [-3.5677e-02, -4.5192e-02, -1.0607e-01],\n",
       "                        [-9.4804e-02,  2.3250e-02,  6.2559e-02]],\n",
       "              \n",
       "                       [[-6.3081e-03,  4.2599e-02, -7.5690e-03],\n",
       "                        [ 5.1253e-02,  4.0515e-02, -5.7520e-02],\n",
       "                        [ 5.7111e-02,  5.1823e-02,  4.7143e-02],\n",
       "                        [ 2.2461e-02, -6.6626e-02, -1.0621e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9134e-02, -8.5371e-02, -3.8116e-02],\n",
       "                        [ 5.3915e-02,  2.7633e-02, -3.7365e-02],\n",
       "                        [ 1.2900e-01,  8.1674e-02,  8.0561e-02],\n",
       "                        [ 1.5608e-01, -1.1914e-01, -1.3709e-02]],\n",
       "              \n",
       "                       [[-5.8702e-02, -8.5733e-02,  6.4893e-02],\n",
       "                        [-3.9602e-02, -6.8616e-02, -3.7243e-02],\n",
       "                        [ 2.3976e-02, -9.6704e-02,  7.1147e-02],\n",
       "                        [ 8.3887e-02, -2.0151e-02,  6.1155e-03]],\n",
       "              \n",
       "                       [[-8.5068e-02, -6.7904e-02, -7.7680e-02],\n",
       "                        [ 1.1463e-01,  1.1052e-02, -1.8302e-02],\n",
       "                        [ 6.6602e-02, -1.1096e-01,  4.7200e-02],\n",
       "                        [ 5.3698e-02,  5.8321e-02, -2.3388e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6772e-02, -1.4976e-01, -1.4953e-01],\n",
       "                        [-3.1455e-03, -9.4166e-02,  6.9995e-02],\n",
       "                        [-1.0035e-01, -1.2528e-01, -6.3228e-02],\n",
       "                        [-3.8311e-02,  5.0945e-02,  3.3599e-02]],\n",
       "              \n",
       "                       [[ 3.2158e-03, -2.0903e-03,  9.8334e-02],\n",
       "                        [ 3.4128e-04, -5.8101e-02,  4.6777e-02],\n",
       "                        [-4.6251e-02,  9.1209e-02,  1.8657e-02],\n",
       "                        [-3.4084e-02, -1.6892e-03,  2.2602e-03]],\n",
       "              \n",
       "                       [[ 5.3571e-02, -7.0039e-02, -1.1484e-01],\n",
       "                        [ 7.4897e-03, -2.7334e-02, -7.7300e-02],\n",
       "                        [ 2.5829e-02,  9.8096e-02, -6.7997e-02],\n",
       "                        [ 1.1348e-02,  6.9737e-02,  4.0680e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9770e-02,  2.9567e-03, -5.5004e-02],\n",
       "                        [ 7.1440e-02, -4.1879e-02,  4.8232e-02],\n",
       "                        [-4.9880e-02, -2.1065e-03, -9.2244e-02],\n",
       "                        [-5.5515e-02, -3.1889e-02,  3.1757e-02]],\n",
       "              \n",
       "                       [[ 5.8752e-03,  2.5827e-02, -2.7013e-02],\n",
       "                        [-7.9076e-02, -4.8216e-02,  4.0905e-02],\n",
       "                        [ 9.9630e-02, -5.7664e-02, -3.7622e-02],\n",
       "                        [ 4.4984e-02,  6.2595e-02, -7.2440e-02]],\n",
       "              \n",
       "                       [[-2.9111e-02, -1.0349e-01,  1.7516e-02],\n",
       "                        [-1.0660e-02, -5.5820e-02,  2.9357e-02],\n",
       "                        [-1.6260e-02, -8.7994e-02, -1.2805e-01],\n",
       "                        [ 7.4158e-02, -3.7163e-02,  9.3729e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.0632e-02, -3.6609e-03, -7.5357e-02],\n",
       "                        [-7.3660e-02,  5.3567e-02, -1.1610e-01],\n",
       "                        [ 2.6491e-02, -3.1865e-02, -4.0824e-02],\n",
       "                        [-4.9050e-02, -5.3858e-02, -8.0473e-02]],\n",
       "              \n",
       "                       [[-9.7318e-03,  6.8673e-02, -4.6261e-02],\n",
       "                        [-1.7845e-02,  3.0439e-02, -8.5027e-03],\n",
       "                        [ 4.5034e-03, -6.4883e-02, -2.2400e-02],\n",
       "                        [ 5.7361e-02, -1.4868e-02, -5.4676e-02]],\n",
       "              \n",
       "                       [[-3.4495e-03, -3.6830e-02, -6.5627e-02],\n",
       "                        [ 2.6057e-02, -6.9939e-02, -1.4990e-02],\n",
       "                        [-2.2762e-02,  1.9365e-02, -2.2255e-02],\n",
       "                        [ 2.8439e-02,  4.0380e-02,  7.9556e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.6076e-02,  5.1171e-02,  4.7517e-02],\n",
       "                        [ 1.2251e-02,  9.2591e-02,  5.2470e-02],\n",
       "                        [-1.7505e-02,  7.1931e-02,  6.0575e-02],\n",
       "                        [-7.9889e-02,  6.8703e-02,  5.4487e-02]],\n",
       "              \n",
       "                       [[ 7.9880e-02,  8.6773e-02,  3.8862e-02],\n",
       "                        [ 8.6170e-02,  1.3210e-02, -1.2842e-02],\n",
       "                        [ 2.4658e-02,  3.4489e-02, -2.6050e-03],\n",
       "                        [ 6.1890e-02,  6.5879e-02,  2.5390e-02]],\n",
       "              \n",
       "                       [[-1.6115e-02,  1.7610e-03, -3.5708e-02],\n",
       "                        [ 6.1660e-03, -2.0150e-02, -9.1327e-02],\n",
       "                        [ 1.9976e-04,  4.5097e-02, -7.5562e-02],\n",
       "                        [ 1.3402e-01,  4.4442e-02, -2.9714e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.6397e-02, -4.1789e-02, -2.4954e-02],\n",
       "                        [-1.6256e-02, -8.6274e-03, -1.4012e-02],\n",
       "                        [ 7.1119e-02, -1.0918e-01, -1.2305e-01],\n",
       "                        [ 2.8146e-02, -4.7580e-02,  4.9929e-02]],\n",
       "              \n",
       "                       [[ 1.0345e-04,  2.2565e-02,  4.6622e-03],\n",
       "                        [-7.4097e-03,  5.8946e-02,  5.4224e-02],\n",
       "                        [ 4.7908e-02, -3.4959e-02, -6.2349e-02],\n",
       "                        [-6.2882e-02, -7.9578e-03,  3.2950e-02]],\n",
       "              \n",
       "                       [[-9.1306e-03, -2.8850e-02, -3.6978e-03],\n",
       "                        [ 5.5275e-02, -1.8021e-02, -1.0290e-01],\n",
       "                        [-6.5673e-02,  6.1162e-02, -4.9541e-03],\n",
       "                        [-8.3392e-02, -2.4895e-02, -3.2739e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4040e-02, -1.5854e-01,  6.2690e-02],\n",
       "                        [ 9.6211e-02, -1.3602e-01, -3.1587e-02],\n",
       "                        [ 4.8047e-02, -3.5779e-02, -4.7167e-02],\n",
       "                        [ 1.0744e-01,  1.3185e-02, -1.3334e-01]],\n",
       "              \n",
       "                       [[ 5.8681e-02, -2.9328e-02, -2.2824e-02],\n",
       "                        [ 2.2114e-02,  3.0273e-02, -2.6941e-02],\n",
       "                        [-1.0922e-02,  6.2536e-02, -6.2389e-02],\n",
       "                        [-1.3360e-02,  3.5632e-02, -1.7909e-02]],\n",
       "              \n",
       "                       [[ 6.3825e-02, -9.1503e-02,  8.4522e-02],\n",
       "                        [-1.2529e-02, -1.2038e-01,  7.6447e-02],\n",
       "                        [-7.1655e-02, -7.3781e-02, -3.6535e-02],\n",
       "                        [ 9.1029e-02,  4.9963e-02, -4.5448e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.2187e-02, -1.3787e-01,  5.3711e-02],\n",
       "                        [-4.4315e-03, -6.2597e-02, -6.0056e-02],\n",
       "                        [ 5.1967e-02,  3.3513e-02, -2.0549e-02],\n",
       "                        [-5.3779e-02,  8.0840e-02, -1.1504e-01]],\n",
       "              \n",
       "                       [[-3.1214e-02, -2.5486e-02, -1.1092e-02],\n",
       "                        [-3.6947e-02,  6.3473e-03, -9.7566e-03],\n",
       "                        [-6.3076e-03,  3.1926e-02, -1.3763e-01],\n",
       "                        [ 1.3452e-02, -4.3924e-02, -7.3957e-02]],\n",
       "              \n",
       "                       [[-4.6503e-02,  1.1414e-01,  3.4218e-02],\n",
       "                        [ 2.6811e-02, -4.9547e-02,  4.4613e-02],\n",
       "                        [-2.9896e-03, -1.2553e-01, -3.0134e-02],\n",
       "                        [ 5.1578e-02,  4.0343e-02, -9.0093e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0279e-02,  7.8301e-02, -8.6144e-02],\n",
       "                        [ 8.4868e-02, -1.8004e-02, -2.7120e-02],\n",
       "                        [-1.3295e-02,  5.6081e-02,  4.5508e-02],\n",
       "                        [ 5.3028e-02, -1.6990e-02,  7.2980e-02]],\n",
       "              \n",
       "                       [[ 7.4010e-04,  6.8018e-02, -4.6631e-02],\n",
       "                        [ 5.2149e-03, -6.8471e-02,  4.2272e-02],\n",
       "                        [ 4.6854e-02,  5.8614e-02, -5.3773e-02],\n",
       "                        [-3.4247e-02, -4.8458e-02, -4.4061e-02]],\n",
       "              \n",
       "                       [[-6.7942e-03,  2.2005e-02,  2.8178e-02],\n",
       "                        [-1.1804e-02,  5.5683e-03, -3.1108e-02],\n",
       "                        [-1.2811e-01,  3.6254e-02, -5.6342e-02],\n",
       "                        [-4.4057e-02,  2.2928e-02,  1.5912e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5817e-02, -7.6218e-04, -7.7922e-02],\n",
       "                        [ 2.0190e-02,  4.6478e-03, -4.8943e-02],\n",
       "                        [ 1.0204e-01,  1.0559e-02,  3.3225e-02],\n",
       "                        [-2.7014e-02, -5.8255e-02, -3.7431e-02]],\n",
       "              \n",
       "                       [[-7.4838e-02,  8.9702e-03, -2.9424e-02],\n",
       "                        [ 3.4934e-02, -2.8275e-02,  2.8051e-02],\n",
       "                        [ 6.2623e-03, -3.4202e-02, -3.3070e-02],\n",
       "                        [-3.9029e-02, -3.1842e-03, -3.7187e-02]],\n",
       "              \n",
       "                       [[ 1.0673e-01,  3.4237e-02, -8.1346e-02],\n",
       "                        [ 5.8024e-02,  2.8855e-02, -5.0645e-02],\n",
       "                        [-2.8757e-02,  4.6049e-02, -1.1474e-01],\n",
       "                        [ 5.9325e-04, -4.5547e-02, -1.2157e-01]]]])),\n",
       "             ('conv4.bias',\n",
       "              tensor([-0.0040,  0.0100,  0.0007,  0.0250,  0.0217,  0.0046, -0.0126,  0.0101,\n",
       "                       0.0054,  0.0237,  0.0215, -0.0076,  0.0049,  0.0009,  0.0173,  0.0162,\n",
       "                       0.0222,  0.0143,  0.0095, -0.0099, -0.0181, -0.0322, -0.0058, -0.0048,\n",
       "                       0.0008, -0.0047, -0.0126,  0.0100,  0.0052,  0.0099,  0.0147, -0.0172])),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 0.0604, -0.0360,  0.0269,  ..., -0.0056,  0.0107,  0.0440],\n",
       "                      [ 0.0596, -0.1002,  0.0297,  ...,  0.0173,  0.0064, -0.0851],\n",
       "                      [ 0.0958,  0.0825, -0.0382,  ..., -0.0223,  0.0405,  0.0646],\n",
       "                      [ 0.0265, -0.0549, -0.0177,  ..., -0.0184, -0.0474,  0.0194],\n",
       "                      [ 0.0038,  0.0177,  0.0078,  ..., -0.0571, -0.0388,  0.1294]])),\n",
       "             ('fc.bias', tensor([0.0698, 0.0360, 0.0176, 0.0406, 0.0202]))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5906a435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "History (client, train losses):\n",
       "\tLesCorts: {1: 1.8008789670259003e-05, 2: 1.6396968634961564e-05, 3: 1.5599051503317623e-05, 4: 1.4920589018571305e-05, 5: 1.586564123002507e-05, 6: 1.5312826370296365e-05, 7: 1.441099888071158e-05, 8: 1.5922363826216178e-05, 9: 1.5065540786286705e-05, 10: 1.4378315717992738e-05}\n",
       "\tElBorn: {1: 3.354552038008783e-05, 2: 4.391456407370351e-05, 3: 3.96067809787204e-05, 4: 4.340028045115531e-05, 5: 3.519058868711069e-05, 6: 4.67073586059561e-05, 7: 2.604395969713999e-05, 8: 2.1004041088143427e-05, 9: 2.0255671428780323e-05, 10: 2.072920206351162e-05}\n",
       "\tPobleSec: {1: 1.9173772909213737e-05, 2: 1.7683451218310213e-05, 3: 1.7286858881080606e-05, 4: 1.6543134981253575e-05, 5: 1.6228538764907827e-05, 6: 1.5949743838569775e-05, 7: 1.578928327759439e-05, 8: 1.574607851212912e-05, 9: 1.5673683545355572e-05, 10: 1.5712797405366677e-05}\n",
       "\n",
       "History (client, train metrics):\n",
       "\tLesCorts: {1: {'MSE': 0.0023051207, 'RMSE': 0.04801167249099282, 'MAE': 0.027620634, 'R^2': 0.6463610236432858, 'NRMSE': 1.19439222492085}, 2: {'MSE': 0.0020988109, 'RMSE': 0.04581278052055479, 'MAE': 0.027253423, 'R^2': 0.6736977240100718, 'NRMSE': 1.1045384190600909}, 3: {'MSE': 0.001996675, 'RMSE': 0.0446841699103036, 'MAE': 0.026219225, 'R^2': 0.6896268604961423, 'NRMSE': 1.0959551451301899}, 4: {'MSE': 0.001909833, 'RMSE': 0.043701636722159605, 'MAE': 0.02496979, 'R^2': 0.7055337018338098, 'NRMSE': 1.0832670692526074}, 5: {'MSE': 0.0020308015, 'RMSE': 0.04506441493767024, 'MAE': 0.026671495, 'R^2': 0.6899773942584706, 'NRMSE': 1.1036900076608895}, 6: {'MSE': 0.0019600447, 'RMSE': 0.04427239237639404, 'MAE': 0.02725502, 'R^2': 0.6872675409315823, 'NRMSE': 1.1304351622367261}, 7: {'MSE': 0.0018446082, 'RMSE': 0.042948902488054094, 'MAE': 0.025287692, 'R^2': 0.7167697945270499, 'NRMSE': 1.0410779263808827}, 8: {'MSE': 0.0020380572, 'RMSE': 0.04514484682688271, 'MAE': 0.028717246, 'R^2': 0.6793550300383775, 'NRMSE': 1.1656438759358436}, 9: {'MSE': 0.0019283879, 'RMSE': 0.04391341376236872, 'MAE': 0.027685026, 'R^2': 0.662035645035025, 'NRMSE': 1.2605885214753232}, 10: {'MSE': 0.0018404232, 'RMSE': 0.04290015396853515, 'MAE': 0.026320856, 'R^2': 0.6713048843633226, 'NRMSE': 1.2837947439612662}}\n",
       "\tElBorn: {1: {'MSE': 0.0042881574, 'RMSE': 0.06548402437367888, 'MAE': 0.031118134, 'R^2': 0.6498616671768336, 'NRMSE': 1.2382342634702301}, 2: {'MSE': 0.0056167217, 'RMSE': 0.07494479099411554, 'MAE': 0.03742995, 'R^2': 0.609981105185577, 'NRMSE': 1.188186756574241}, 3: {'MSE': 0.0050513605, 'RMSE': 0.07107292357562187, 'MAE': 0.035802267, 'R^2': 0.6098425642609007, 'NRMSE': 1.3083692313314497}, 4: {'MSE': 0.0055248323, 'RMSE': 0.07432921558624131, 'MAE': 0.035820454, 'R^2': 0.5865228037486521, 'NRMSE': 1.328294643281877}, 5: {'MSE': 0.0044669677, 'RMSE': 0.06683537728784392, 'MAE': 0.034407064, 'R^2': 0.6443474874599686, 'NRMSE': 1.260032455104184}, 6: {'MSE': 0.005972485, 'RMSE': 0.07728185464913238, 'MAE': 0.039455194, 'R^2': 0.5821602265068957, 'NRMSE': 1.3017392037955169}, 7: {'MSE': 0.0033319984, 'RMSE': 0.05772346458016225, 'MAE': 0.025604974, 'R^2': 0.7340925815135578, 'NRMSE': 1.0851621445265027}, 8: {'MSE': 0.0026860756, 'RMSE': 0.051827363751128015, 'MAE': 0.023475641, 'R^2': 0.7675697692325685, 'NRMSE': 1.048750404922102}, 9: {'MSE': 0.0025909364, 'RMSE': 0.05090124139725763, 'MAE': 0.022733323, 'R^2': 0.7716197136389045, 'NRMSE': 1.0481472284011453}, 10: {'MSE': 0.0026489738, 'RMSE': 0.05146818276853041, 'MAE': 0.023569241, 'R^2': 0.7732247823364322, 'NRMSE': 1.0356219303504215}}\n",
       "\tPobleSec: {1: {'MSE': 0.002446896, 'RMSE': 0.04946610891222465, 'MAE': 0.023919204, 'R^2': 0.6462877340454035, 'NRMSE': 1.1942830895400176}, 2: {'MSE': 0.0022567282, 'RMSE': 0.047505033870977945, 'MAE': 0.023113908, 'R^2': 0.6823618871190638, 'NRMSE': 1.1108280421363228}, 3: {'MSE': 0.002205986, 'RMSE': 0.04696792590616933, 'MAE': 0.0221258, 'R^2': 0.6969488754248467, 'NRMSE': 1.0864469221405084}, 4: {'MSE': 0.0021109062, 'RMSE': 0.045944599009368876, 'MAE': 0.021402057, 'R^2': 0.7120879527475444, 'NRMSE': 1.0568996073655452}, 5: {'MSE': 0.0020707753, 'RMSE': 0.04550577167306225, 'MAE': 0.020999705, 'R^2': 0.7202219865370127, 'NRMSE': 1.0370909012282135}, 6: {'MSE': 0.002035102, 'RMSE': 0.04511210600818196, 'MAE': 0.020942267, 'R^2': 0.7258164550192661, 'NRMSE': 1.0196332280546945}, 7: {'MSE': 0.0020145893, 'RMSE': 0.044884176088308164, 'MAE': 0.020886498, 'R^2': 0.7275349720644515, 'NRMSE': 1.0251824709969308}, 8: {'MSE': 0.0020090376, 'RMSE': 0.0448222896476627, 'MAE': 0.021133872, 'R^2': 0.7280386792258435, 'NRMSE': 1.0266403033864975}, 9: {'MSE': 0.0019997605, 'RMSE': 0.044718681915532604, 'MAE': 0.021135632, 'R^2': 0.7306297080391522, 'NRMSE': 1.0143467109746473}, 10: {'MSE': 0.0020046397, 'RMSE': 0.04477320304859809, 'MAE': 0.02144789, 'R^2': 0.7302406509813011, 'NRMSE': 1.0116503851666407}}\n",
       "\n",
       "History (client, test losses):\n",
       "\tLesCorts: {1: 1.638515244615237e-05, 2: 1.4189285691997734e-05, 3: 1.3335206044997138e-05, 4: 1.3191093237456533e-05, 5: 1.3087921881740532e-05, 6: 1.2825254493186043e-05, 7: 1.2540215832638768e-05, 8: 1.2955778960563374e-05, 9: 1.290796919622355e-05, 10: 1.2467856221418413e-05}\n",
       "\tElBorn: {1: 3.2951381799297022e-06, 2: 9.230368898322149e-06, 3: 4.586990992144956e-06, 4: 4.70423503499928e-06, 5: 6.026086058064954e-06, 6: 6.586943408879249e-06, 7: 2.894626537665212e-06, 8: 2.3921925781501664e-06, 9: 2.5245345845494582e-06, 10: 2.1839770263483847e-06}\n",
       "\tPobleSec: {1: 1.6769740646191704e-05, 2: 1.580404676863645e-05, 3: 1.575978745992376e-05, 4: 1.520014505496058e-05, 5: 1.4954684861371015e-05, 6: 1.4808487585254425e-05, 7: 1.456983441552954e-05, 8: 1.461888828468839e-05, 9: 1.4465245927911339e-05, 10: 1.4547477787961875e-05}\n",
       "\n",
       "History (client, test metrics):\n",
       "\tLesCorts: {1: {'MSE': 0.00207293, 'RMSE': 0.04552944215744238, 'MAE': 0.029169181, 'R^2': -64.57299642627912, 'NRMSE': 6.21780395706517}, 2: {'MSE': 0.0017973271, 'RMSE': 0.04239489442481186, 'MAE': 0.026734207, 'R^2': -63.063331664522046, 'NRMSE': 3.8138253570725458}, 3: {'MSE': 0.0016869918, 'RMSE': 0.0410730054229912, 'MAE': 0.025901586, 'R^2': -54.808528953361794, 'NRMSE': 3.553355324641089}, 4: {'MSE': 0.0016669165, 'RMSE': 0.0408278891727777, 'MAE': 0.025049374, 'R^2': -20.24039219164219, 'NRMSE': 3.119000486169087}, 5: {'MSE': 0.0016530014, 'RMSE': 0.040657120051556105, 'MAE': 0.025973711, 'R^2': -52.43223588247548, 'NRMSE': 4.252647116217069}, 6: {'MSE': 0.0016200282, 'RMSE': 0.04024957351280915, 'MAE': 0.02548875, 'R^2': -31.42580611078869, 'NRMSE': 3.6085651086032913}, 7: {'MSE': 0.0015854858, 'RMSE': 0.039818158708264065, 'MAE': 0.024596436, 'R^2': -23.442601741968197, 'NRMSE': 2.054873089859516}, 8: {'MSE': 0.0016363167, 'RMSE': 0.04045141098338953, 'MAE': 0.025415787, 'R^2': -32.77554556848319, 'NRMSE': 3.348117085510005}, 9: {'MSE': 0.0016288906, 'RMSE': 0.04035951726152171, 'MAE': 0.026299898, 'R^2': -61.57550685116671, 'NRMSE': 5.374010132649036}, 10: {'MSE': 0.001576774, 'RMSE': 0.039708614369406425, 'MAE': 0.024287926, 'R^2': -30.384575657199754, 'NRMSE': 4.305745604748747}}\n",
       "\tElBorn: {1: {'MSE': 0.0003972304, 'RMSE': 0.01993064000932299, 'MAE': 0.013852525, 'R^2': -8.34736107606877, 'NRMSE': 3.171702335169947}, 2: {'MSE': 0.0010692978, 'RMSE': 0.03270011897859269, 'MAE': 0.020441521, 'R^2': -0.6021635288546491, 'NRMSE': 1.2596389070957188}, 3: {'MSE': 0.0005569732, 'RMSE': 0.023600280010829113, 'MAE': 0.016798751, 'R^2': -2.221853798168504, 'NRMSE': 1.5889508143010649}, 4: {'MSE': 0.0005711292, 'RMSE': 0.023898309632866793, 'MAE': 0.01684287, 'R^2': -3.583672210482895, 'NRMSE': 2.0284110257904797}, 5: {'MSE': 0.0007264416, 'RMSE': 0.026952580950954406, 'MAE': 0.018628959, 'R^2': -3.1676985382721345, 'NRMSE': 1.931463839886631}, 6: {'MSE': 0.00078587176, 'RMSE': 0.028033404326369683, 'MAE': 0.016464947, 'R^2': 0.1869436614808416, 'NRMSE': 0.8163632337339332}, 7: {'MSE': 0.00034299964, 'RMSE': 0.01852024954422913, 'MAE': 0.00981651, 'R^2': 0.18396970985306793, 'NRMSE': 0.7796777113248069}, 8: {'MSE': 0.0002804978, 'RMSE': 0.016748068527285536, 'MAE': 0.010514663, 'R^2': -1.200521644279823, 'NRMSE': 1.5752684348398334}, 9: {'MSE': 0.0002952398, 'RMSE': 0.01718254322676745, 'MAE': 0.010541887, 'R^2': -1.0788868743588864, 'NRMSE': 1.533051542845743}, 10: {'MSE': 0.0002591738, 'RMSE': 0.016098875773444536, 'MAE': 0.0099342, 'R^2': -1.6472026863075964, 'NRMSE': 1.796922094338042}}\n",
       "\tPobleSec: {1: {'MSE': 0.0021243112, 'RMSE': 0.046090250266291974, 'MAE': 0.023261935, 'R^2': 0.5681561158635653, 'NRMSE': 1.3183553887459314}, 2: {'MSE': 0.0020029545, 'RMSE': 0.044754379484383724, 'MAE': 0.022450808, 'R^2': 0.5945921406616628, 'NRMSE': 1.256542636350604}, 3: {'MSE': 0.0019974336, 'RMSE': 0.04469265714644751, 'MAE': 0.021630963, 'R^2': 0.603321499121396, 'NRMSE': 1.2498865663628593}, 4: {'MSE': 0.0019266872, 'RMSE': 0.043894045118084354, 'MAE': 0.021076683, 'R^2': 0.6182177098472337, 'NRMSE': 1.217692750942793}, 5: {'MSE': 0.0018955513, 'RMSE': 0.04353792986499475, 'MAE': 0.020771574, 'R^2': 0.6270209625471171, 'NRMSE': 1.2013652845732428}, 6: {'MSE': 0.0018767841, 'RMSE': 0.043321866757017796, 'MAE': 0.020837499, 'R^2': 0.6291207346506954, 'NRMSE': 1.1890553566920041}, 7: {'MSE': 0.0018467611, 'RMSE': 0.04297395831750811, 'MAE': 0.020682964, 'R^2': 0.6370839112806104, 'NRMSE': 1.1801977366242777}, 8: {'MSE': 0.0018530771, 'RMSE': 0.043047381922078874, 'MAE': 0.020951526, 'R^2': 0.6367991165191359, 'NRMSE': 1.184533624429191}, 9: {'MSE': 0.0018331667, 'RMSE': 0.04281549595962406, 'MAE': 0.020900013, 'R^2': 0.6432201335858956, 'NRMSE': 1.1736129451350634}, 10: {'MSE': 0.0018434692, 'RMSE': 0.0429356404100326, 'MAE': 0.021287855, 'R^2': 0.6391827047643388, 'NRMSE': 1.1763607227928754}}\n",
       "\n",
       "History (global averaged train losses):\n",
       "\t[0.0002441519399219304, 4.6233633091896374e-05, 3.3587530034260747e-05, 2.9885701610362787e-05, 2.8141027327402098e-05, 2.672608394822148e-05, 2.5037258199752294e-05, 2.224480866346542e-05, 2.03299528594244e-05, 2.1794214230259507e-05, 2.033354443259191e-05]\n",
       "\n",
       "History (global averaged train metrics):\n",
       "\tMSE: [0.03115694680914932, 0.005904030242798447, 0.004290847142509239, 0.0038166499575833074, 0.0035939070625719202, 0.0034126759221927505, 0.003197333222622806, 0.002841332689768344, 0.0025968824938350497, 0.002782983811437545, 0.002596838549694411]\n",
       "\tRMSE: [0.17631755559977114, 0.07638440772118198, 0.06494483626823841, 0.061639440807652074, 0.05976405179096264, 0.05828889451829662, 0.056475101046264006, 0.053175540679234516, 0.050789451337349786, 0.05267551014686017, 0.05078833583297477]\n",
       "\tMAE: [0.11173675091206972, 0.04323906788707774, 0.03574316753376624, 0.03493457131426129, 0.032717437469042265, 0.03150648523857463, 0.029564964116669232, 0.028174677776713078, 0.027184485229452084, 0.028792115245998402, 0.02758032424000814]\n",
       "\tR^2: [-1.4799923355560998, 0.39462648860909844, 0.5494311371710964, 0.5519505162561661, 0.6041069873964712, 0.6208893913192856, 0.6503948951345391, 0.6706804006916993, 0.6816479269700295, 0.66257313313883, 0.6813687251341678]\n",
       "\tNRMSE: [2.0280026184161644, 1.5214615915561138, 1.3606857719602343, 1.351057689393835, 1.274373406290706, 1.242469063363655, 1.1967200302877574, 1.1820153343009971, 1.1753754980069901, 1.207407899024761, 1.1835285885910614]\n",
       "\n",
       "History (global averaged test losses):\n",
       "\t[0.00021582108138021956, 4.217795118792882e-05, 3.274669780783817e-05, 2.771957150638e-05, 2.6128021764480203e-05, 2.4300540864582584e-05, 2.2552206157234167e-05, 1.975346547292656e-05, 1.7841065447950733e-05, 1.9007008161646868e-05, 1.7617426737892406e-05]\n",
       "\n",
       "History (global averaged test metrics):\n",
       "\tMSE: [0.027355539481903095, 0.005362678240449571, 0.004154909005093146, 0.0035197026007157636, 0.0033165546824413124, 0.0030840745543540176, 0.002860524473072702, 0.002503262911050169, 0.002258597946412108, 0.0024099019040920437, 0.002230140972651716]\n",
       "\tRMSE: [0.16153551059773, 0.06865250589577905, 0.06051668368587582, 0.05621175177549963, 0.05453951658013764, 0.052736984272056614, 0.0510910081260413, 0.04784616611176218, 0.04563646717182473, 0.04701931912537866, 0.045417432626036654]\n",
       "\tMAE: [0.10261552640205876, 0.04105634804314973, 0.03422047044187812, 0.03255193469256268, 0.030698978217095663, 0.02937999296724641, 0.027460851794477395, 0.02625071772103191, 0.025385795418798002, 0.026809952134244648, 0.02595350681851805]\n",
       "\tR^2: [-27.664060642323744, -28.74377623265532, -48.72855944097359, -4.475570888168727, -6.308715989896681, -4.296072258938082, -7.370809448290642, -8.039418654351561, -15.265570455589923, -23.35885636118412, -36.862539683319376]\n",
       "\tNRMSE: [3.6311943151307706, 3.9343845275842297, 4.048627821638901, 2.0037290526204665, 1.9254120393197525, 1.6646510554832101, 2.078397204119554, 2.242658516699674, 2.678439105287888, 3.15371001486553, 3.550418509505418]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a39106e1a9d6d153b7400628e7589ff266b5caee5b0db427f0903be982155882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
